{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnvgg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsRjEW2_Fbrv",
        "outputId": "3ecb26cb-e7d0-4db4-e199-90af4e73f238"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy8D9M0GFpFz"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh3sqT6kFrZr",
        "outputId": "8e2b637a-9209-4179-ff96-e8e6bf07f769"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "print(os.getcwd())\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiOSY63EFs3b"
      },
      "source": [
        "train_labels = pd.read_csv('/content/gdrive/MyDrive/Xray dataset/labels_train.csv')\n",
        "test_labels = pd.read_csv('/content/gdrive/MyDrive/Xray dataset/sample_submission.csv')\n",
        "dataset_url = '/content/gdrive/MyDrive/Xray dataset'\n",
        "directory_train = '/content/gdrive/MyDrive/Xray dataset/train_images/'\n",
        "directory_test = '/content/gdrive/MyDrive/Xray dataset/test_images/'\n",
        "trainingNPY = '/content/gdrive/MyDrive/pneumonia/training.npy'\n",
        "testingNPY = '/content/gdrive/MyDrive/pneumonia/testing.npy'\n",
        "training224= '/content/gdrive/MyDrive/Colab Notebooks/training224.npy'\n",
        "testing224= '/content/gdrive/MyDrive/Colab Notebooks/testing224.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yH6miqQGvbg"
      },
      "source": [
        "#x_train=np.load(trainingNPY)\n",
        "#x_test=np.load(testingNPY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsDES-ZQ5BQ",
        "outputId": "3f72e3b6-b45d-4beb-bcf3-9b4f3cc8d41f"
      },
      "source": [
        "training_set_image = [ ]\n",
        "\n",
        "for i in tqdm(range(train_labels.shape[0])):\n",
        "  # img = image.load_img(directory_train+train_labels['file_name'][i], target_size=(128,128,3))\n",
        "  img = image.load_img(directory_train+train_labels['file_name'][i], target_size=(224,224,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255.0\n",
        "  training_set_image.append(img)\n",
        "x_train = np.array(training_set_image,dtype=\"float32\")\n",
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4672/4672 [33:30<00:00,  2.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[[[0.19215687 0.19215687 0.19215687]\n",
            "   [0.19215687 0.19215687 0.19215687]\n",
            "   [0.19215687 0.19215687 0.19215687]\n",
            "   ...\n",
            "   [0.10980392 0.10980392 0.10980392]\n",
            "   [0.10196079 0.10196079 0.10196079]\n",
            "   [0.09411765 0.09411765 0.09411765]]\n",
            "\n",
            "  [[0.2        0.2        0.2       ]\n",
            "   [0.20392157 0.20392157 0.20392157]\n",
            "   [0.20392157 0.20392157 0.20392157]\n",
            "   ...\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.10196079 0.10196079 0.10196079]\n",
            "   [0.09411765 0.09411765 0.09411765]]\n",
            "\n",
            "  [[0.20784314 0.20784314 0.20784314]\n",
            "   [0.20784314 0.20784314 0.20784314]\n",
            "   [0.20784314 0.20784314 0.20784314]\n",
            "   ...\n",
            "   [0.13725491 0.13725491 0.13725491]\n",
            "   [0.09019608 0.09019608 0.09019608]\n",
            "   [0.10588235 0.10588235 0.10588235]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.10980392 0.10980392 0.10980392]\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.10588235 0.10588235 0.10588235]\n",
            "   ...\n",
            "   [0.16862746 0.16862746 0.16862746]\n",
            "   [0.16862746 0.16862746 0.16862746]\n",
            "   [0.16470589 0.16470589 0.16470589]]\n",
            "\n",
            "  [[0.11372549 0.11372549 0.11372549]\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.10588235 0.10588235 0.10588235]\n",
            "   ...\n",
            "   [0.16470589 0.16470589 0.16470589]\n",
            "   [0.16470589 0.16470589 0.16470589]\n",
            "   [0.16862746 0.16862746 0.16862746]]\n",
            "\n",
            "  [[0.11372549 0.11372549 0.11372549]\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.10588235 0.10588235 0.10588235]\n",
            "   ...\n",
            "   [0.16470589 0.16470589 0.16470589]\n",
            "   [0.16470589 0.16470589 0.16470589]\n",
            "   [0.16078432 0.16078432 0.16078432]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.48235294 0.48235294 0.48235294]\n",
            "   [0.49019608 0.49019608 0.49019608]\n",
            "   [0.5176471  0.5176471  0.5176471 ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.46666667 0.46666667 0.46666667]\n",
            "   [0.52156866 0.52156866 0.52156866]\n",
            "   [0.5176471  0.5176471  0.5176471 ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.49411765 0.49411765 0.49411765]\n",
            "   [0.5176471  0.5176471  0.5176471 ]\n",
            "   [0.5254902  0.5254902  0.5254902 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.29803923 0.29803923 0.29803923]\n",
            "   [0.3019608  0.3019608  0.3019608 ]\n",
            "   [0.30588236 0.30588236 0.30588236]\n",
            "   ...\n",
            "   [0.2        0.2        0.2       ]\n",
            "   [0.2509804  0.2509804  0.2509804 ]\n",
            "   [0.22745098 0.22745098 0.22745098]]\n",
            "\n",
            "  [[0.3137255  0.3137255  0.3137255 ]\n",
            "   [0.32941177 0.32941177 0.32941177]\n",
            "   [0.3372549  0.3372549  0.3372549 ]\n",
            "   ...\n",
            "   [0.3019608  0.3019608  0.3019608 ]\n",
            "   [0.26666668 0.26666668 0.26666668]\n",
            "   [0.29803923 0.29803923 0.29803923]]\n",
            "\n",
            "  [[0.3372549  0.3372549  0.3372549 ]\n",
            "   [0.34117648 0.34117648 0.34117648]\n",
            "   [0.33333334 0.33333334 0.33333334]\n",
            "   ...\n",
            "   [0.23529412 0.23529412 0.23529412]\n",
            "   [0.20784314 0.20784314 0.20784314]\n",
            "   [0.33333334 0.33333334 0.33333334]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.0627451  0.0627451  0.0627451 ]\n",
            "   [0.09019608 0.09019608 0.09019608]\n",
            "   [0.1764706  0.1764706  0.1764706 ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.03921569 0.03921569 0.03921569]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   [0.14901961 0.14901961 0.14901961]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.03529412 0.03529412 0.03529412]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.10980392 0.10980392 0.10980392]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.5921569  0.5921569  0.5921569 ]\n",
            "   [0.5882353  0.5882353  0.5882353 ]\n",
            "   [0.5764706  0.5764706  0.5764706 ]\n",
            "   ...\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.10980392 0.10980392 0.10980392]\n",
            "   [0.09803922 0.09803922 0.09803922]]\n",
            "\n",
            "  [[0.5803922  0.5803922  0.5803922 ]\n",
            "   [0.54901963 0.54901963 0.54901963]\n",
            "   [0.4862745  0.4862745  0.4862745 ]\n",
            "   ...\n",
            "   [0.1254902  0.1254902  0.1254902 ]\n",
            "   [0.12156863 0.12156863 0.12156863]\n",
            "   [0.10980392 0.10980392 0.10980392]]\n",
            "\n",
            "  [[0.54901963 0.54901963 0.54901963]\n",
            "   [0.49803922 0.49803922 0.49803922]\n",
            "   [0.38039216 0.38039216 0.38039216]\n",
            "   ...\n",
            "   [0.12941177 0.12941177 0.12941177]\n",
            "   [0.1254902  0.1254902  0.1254902 ]\n",
            "   [0.11372549 0.11372549 0.11372549]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.04705882 0.04705882 0.04705882]]\n",
            "\n",
            "  [[0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.04705882 0.04705882 0.04705882]]\n",
            "\n",
            "  [[0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   [0.04313726 0.04313726 0.04313726]\n",
            "   ...\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   [0.04705882 0.04705882 0.04705882]]]\n",
            "\n",
            "\n",
            " [[[0.34509805 0.34509805 0.34509805]\n",
            "   [0.3529412  0.3529412  0.3529412 ]\n",
            "   [0.31764707 0.31764707 0.31764707]\n",
            "   ...\n",
            "   [0.23529412 0.23529412 0.23529412]\n",
            "   [0.23921569 0.23921569 0.23921569]\n",
            "   [0.32941177 0.32941177 0.32941177]]\n",
            "\n",
            "  [[0.40392157 0.40392157 0.40392157]\n",
            "   [0.3764706  0.3764706  0.3764706 ]\n",
            "   [0.3529412  0.3529412  0.3529412 ]\n",
            "   ...\n",
            "   [0.2784314  0.2784314  0.2784314 ]\n",
            "   [0.23529412 0.23529412 0.23529412]\n",
            "   [0.3019608  0.3019608  0.3019608 ]]\n",
            "\n",
            "  [[0.4117647  0.4117647  0.4117647 ]\n",
            "   [0.38039216 0.38039216 0.38039216]\n",
            "   [0.3529412  0.3529412  0.3529412 ]\n",
            "   ...\n",
            "   [0.3137255  0.3137255  0.3137255 ]\n",
            "   [0.29411766 0.29411766 0.29411766]\n",
            "   [0.27450982 0.27450982 0.27450982]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05882353 0.05882353 0.05882353]\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.14509805 0.14509805 0.14509805]\n",
            "   ...\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   [0.08627451 0.08627451 0.08627451]\n",
            "   [0.08627451 0.08627451 0.08627451]]\n",
            "\n",
            "  [[0.05490196 0.05490196 0.05490196]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.14509805 0.14509805 0.14509805]\n",
            "   ...\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   [0.08627451 0.08627451 0.08627451]\n",
            "   [0.08627451 0.08627451 0.08627451]]\n",
            "\n",
            "  [[0.05098039 0.05098039 0.05098039]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.14901961 0.14901961 0.14901961]\n",
            "   ...\n",
            "   [0.08235294 0.08235294 0.08235294]\n",
            "   [0.08627451 0.08627451 0.08627451]\n",
            "   [0.08627451 0.08627451 0.08627451]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.22745098 0.22745098 0.22745098]\n",
            "   ...\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.1882353  0.1882353  0.1882353 ]\n",
            "   ...\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   [0.02352941 0.02352941 0.02352941]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.29411766 0.29411766 0.29411766]\n",
            "   ...\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.01960784 0.01960784 0.01960784]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.03529412 0.03529412 0.03529412]\n",
            "   [0.11372549 0.11372549 0.11372549]\n",
            "   [0.13725491 0.13725491 0.13725491]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.03137255 0.03137255 0.03137255]\n",
            "   [0.12941177 0.12941177 0.12941177]\n",
            "   [0.12941177 0.12941177 0.12941177]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.03529412 0.03529412 0.03529412]\n",
            "   [0.13333334 0.13333334 0.13333334]\n",
            "   [0.16078432 0.16078432 0.16078432]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpZ7mcTOQ6QE",
        "outputId": "9af95874-6240-4099-bf1b-e666cf76bd90"
      },
      "source": [
        "testing_set_image = [ ]\n",
        "\n",
        "for i in tqdm(range(test_labels.shape[0])):\n",
        "  img = image.load_img(directory_test+test_labels['file_name'][i], target_size=(224,224,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255.0\n",
        "  testing_set_image.append(img)\n",
        "x_test = np.array(testing_set_image,dtype=\"float32\")\n",
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [07:43<00:00,  2.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[[[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.0627451  0.0627451  0.0627451 ]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.03921569 0.03921569 0.03921569]\n",
            "   [0.03137255 0.03137255 0.03137255]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.03529412 0.03529412 0.03529412]\n",
            "   [0.02745098 0.02745098 0.02745098]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.02745098 0.02745098 0.02745098]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   ...\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.01960784 0.01960784 0.01960784]\n",
            "   [0.06666667 0.06666667 0.06666667]\n",
            "   ...\n",
            "   [0.03921569 0.03921569 0.03921569]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.01176471 0.01176471 0.01176471]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.04705882 0.04705882 0.04705882]\n",
            "   ...\n",
            "   [0.02745098 0.02745098 0.02745098]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.41568628 0.41568628 0.41568628]\n",
            "   [0.41960785 0.41960785 0.41960785]\n",
            "   [0.43137255 0.43137255 0.43137255]\n",
            "   ...\n",
            "   [0.2784314  0.2784314  0.2784314 ]\n",
            "   [0.26666668 0.26666668 0.26666668]\n",
            "   [0.29411766 0.29411766 0.29411766]]\n",
            "\n",
            "  [[0.39215687 0.39215687 0.39215687]\n",
            "   [0.39607844 0.39607844 0.39607844]\n",
            "   [0.42352942 0.42352942 0.42352942]\n",
            "   ...\n",
            "   [0.25490198 0.25490198 0.25490198]\n",
            "   [0.27058825 0.27058825 0.27058825]\n",
            "   [0.27450982 0.27450982 0.27450982]]\n",
            "\n",
            "  [[0.40392157 0.40392157 0.40392157]\n",
            "   [0.42745098 0.42745098 0.42745098]\n",
            "   [0.43529412 0.43529412 0.43529412]\n",
            "   ...\n",
            "   [0.2784314  0.2784314  0.2784314 ]\n",
            "   [0.2784314  0.2784314  0.2784314 ]\n",
            "   [0.28235295 0.28235295 0.28235295]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.         0.         0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.8509804  0.8509804  0.8509804 ]\n",
            "   [0.77254903 0.77254903 0.77254903]\n",
            "   [0.7490196  0.7490196  0.7490196 ]\n",
            "   ...\n",
            "   [0.42745098 0.42745098 0.42745098]\n",
            "   [0.4627451  0.4627451  0.4627451 ]\n",
            "   [0.44705883 0.44705883 0.44705883]]\n",
            "\n",
            "  [[0.8745098  0.8745098  0.8745098 ]\n",
            "   [0.827451   0.827451   0.827451  ]\n",
            "   [0.7882353  0.7882353  0.7882353 ]\n",
            "   ...\n",
            "   [0.46666667 0.46666667 0.46666667]\n",
            "   [0.44705883 0.44705883 0.44705883]\n",
            "   [0.43529412 0.43529412 0.43529412]]\n",
            "\n",
            "  [[0.8745098  0.8745098  0.8745098 ]\n",
            "   [0.8352941  0.8352941  0.8352941 ]\n",
            "   [0.8039216  0.8039216  0.8039216 ]\n",
            "   ...\n",
            "   [0.4862745  0.4862745  0.4862745 ]\n",
            "   [0.48235294 0.48235294 0.48235294]\n",
            "   [0.45882353 0.45882353 0.45882353]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05490196 0.05490196 0.05490196]\n",
            "   [0.24313726 0.24313726 0.24313726]\n",
            "   [0.3137255  0.3137255  0.3137255 ]\n",
            "   ...\n",
            "   [0.16078432 0.16078432 0.16078432]\n",
            "   [0.19215687 0.19215687 0.19215687]\n",
            "   [0.2784314  0.2784314  0.2784314 ]]\n",
            "\n",
            "  [[0.08235294 0.08235294 0.08235294]\n",
            "   [0.2627451  0.2627451  0.2627451 ]\n",
            "   [0.33333334 0.33333334 0.33333334]\n",
            "   ...\n",
            "   [0.16862746 0.16862746 0.16862746]\n",
            "   [0.20392157 0.20392157 0.20392157]\n",
            "   [0.2627451  0.2627451  0.2627451 ]]\n",
            "\n",
            "  [[0.05490196 0.05490196 0.05490196]\n",
            "   [0.27058825 0.27058825 0.27058825]\n",
            "   [0.3372549  0.3372549  0.3372549 ]\n",
            "   ...\n",
            "   [0.16862746 0.16862746 0.16862746]\n",
            "   [0.20392157 0.20392157 0.20392157]\n",
            "   [0.33333334 0.33333334 0.33333334]]]\n",
            "\n",
            "\n",
            " [[[0.3254902  0.3254902  0.3254902 ]\n",
            "   [0.30588236 0.30588236 0.30588236]\n",
            "   [0.3137255  0.3137255  0.3137255 ]\n",
            "   ...\n",
            "   [0.4627451  0.4627451  0.4627451 ]\n",
            "   [0.50980395 0.50980395 0.50980395]\n",
            "   [0.5058824  0.5058824  0.5058824 ]]\n",
            "\n",
            "  [[0.31764707 0.31764707 0.31764707]\n",
            "   [0.30588236 0.30588236 0.30588236]\n",
            "   [0.30980393 0.30980393 0.30980393]\n",
            "   ...\n",
            "   [0.4862745  0.4862745  0.4862745 ]\n",
            "   [0.5137255  0.5137255  0.5137255 ]\n",
            "   [0.49411765 0.49411765 0.49411765]]\n",
            "\n",
            "  [[0.3019608  0.3019608  0.3019608 ]\n",
            "   [0.3019608  0.3019608  0.3019608 ]\n",
            "   [0.3019608  0.3019608  0.3019608 ]\n",
            "   ...\n",
            "   [0.5882353  0.5882353  0.5882353 ]\n",
            "   [0.52156866 0.52156866 0.52156866]\n",
            "   [0.5921569  0.5921569  0.5921569 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.3019608  0.3019608  0.3019608 ]\n",
            "   [0.20392157 0.20392157 0.20392157]\n",
            "   [0.16862746 0.16862746 0.16862746]\n",
            "   ...\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.0627451  0.0627451  0.0627451 ]\n",
            "   [0.05098039 0.05098039 0.05098039]]\n",
            "\n",
            "  [[0.30588236 0.30588236 0.30588236]\n",
            "   [0.20784314 0.20784314 0.20784314]\n",
            "   [0.15686275 0.15686275 0.15686275]\n",
            "   ...\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05098039 0.05098039 0.05098039]]\n",
            "\n",
            "  [[0.30980393 0.30980393 0.30980393]\n",
            "   [0.21176471 0.21176471 0.21176471]\n",
            "   [0.16470589 0.16470589 0.16470589]\n",
            "   ...\n",
            "   [0.05490196 0.05490196 0.05490196]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05490196 0.05490196 0.05490196]]]\n",
            "\n",
            "\n",
            " [[[0.00392157 0.00392157 0.00392157]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.02352941 0.02352941 0.02352941]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.01568628 0.01568628 0.01568628]\n",
            "   [0.01568628 0.01568628 0.01568628]]\n",
            "\n",
            "  [[0.01568628 0.01568628 0.01568628]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.07843138 0.07843138 0.07843138]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  [[0.07450981 0.07450981 0.07450981]\n",
            "   [0.09411765 0.09411765 0.09411765]\n",
            "   [0.10980392 0.10980392 0.10980392]\n",
            "   ...\n",
            "   [0.00784314 0.00784314 0.00784314]\n",
            "   [0.00392157 0.00392157 0.00392157]\n",
            "   [0.00784314 0.00784314 0.00784314]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.06666667 0.06666667 0.06666667]\n",
            "   [0.0627451  0.0627451  0.0627451 ]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.15294118 0.15294118 0.15294118]\n",
            "   [0.22352941 0.22352941 0.22352941]\n",
            "   [0.31764707 0.31764707 0.31764707]]\n",
            "\n",
            "  [[0.0627451  0.0627451  0.0627451 ]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.15294118 0.15294118 0.15294118]\n",
            "   [0.22352941 0.22352941 0.22352941]\n",
            "   [0.31764707 0.31764707 0.31764707]]\n",
            "\n",
            "  [[0.05882353 0.05882353 0.05882353]\n",
            "   [0.05098039 0.05098039 0.05098039]\n",
            "   [0.05882353 0.05882353 0.05882353]\n",
            "   ...\n",
            "   [0.15294118 0.15294118 0.15294118]\n",
            "   [0.22745098 0.22745098 0.22745098]\n",
            "   [0.32156864 0.32156864 0.32156864]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEIt7AqtSkmH",
        "outputId": "51390c57-a77c-43b0-eacc-28e0be3dea6d"
      },
      "source": [
        "print(\"Saving training image binary...\")\n",
        "np.save(\"training224\",x_train) # Saves as \"training.npy\"\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving training image binary...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-7v78GfSlXE",
        "outputId": "1ccae728-aa93-4a3c-f546-7495503172c7"
      },
      "source": [
        "print(\"Saving testing image binary...\")\n",
        "np.save(\"testing224\",x_test) \n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving testing image binary...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGSof_WicLZg"
      },
      "source": [
        "x_train=np.load(training224)\n",
        "x_test=np.load(testing224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LL1UQ_aFyBS"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "x_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "x_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tiqyCsCJjkW",
        "outputId": "c6cc0559-b7e0-4955-a3ab-7e854e575ed7"
      },
      "source": [
        "y_train = np.array(train_labels.drop(['file_name'],axis=1))\n",
        "y_train.shape\n",
        "print(y_train)\n",
        "y_test = np.array(test_labels.drop(['file_name'],axis=1))\n",
        "y_test.shape\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [2]\n",
            " [2]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nz6bgliJn3z",
        "outputId": "e5759b33-b14e-40c3-ae3c-4890b8bed3ef"
      },
      "source": [
        "num_classes=3\n",
        "depth=20\n",
        "\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean\n",
        "\n",
        "\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "t_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "t_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "print('y_train (labels) shape:', y_train.shape)\n",
        "print('t_train (one-hot rep) shape:', t_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train (labels) shape: (4672, 1)\n",
            "t_train (one-hot rep) shape: (4672, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ1ReCUsJpkV"
      },
      "source": [
        "tempx_train=x_train[500:]\n",
        "tempt_train=t_train[500:] \n",
        "tempx_test=x_train[:500] \n",
        "tempt_test=t_train[:500]\n",
        "tempy_train=y_train[500:]\n",
        "tempy_test=y_test[:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e67R5rw0JqoP"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uawof49iJw0V"
      },
      "source": [
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfflQhMwJ0h3"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=input_shape),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
        "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
        "    Flatten(),\n",
        "    Dense(units=3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q8Xv8WBKVja"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "X9RP3TNbJ5GX",
        "outputId": "a0b86ee9-82bc-41e8-8dae-45346fd3e08d"
      },
      "source": [
        "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
        "          steps_per_epoch=len(x_train) / 32, epochs=10,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "146/146 - 54s - loss: 27.0013 - accuracy: 0.3373\n",
            "Epoch 2/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c9f95e84ab4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(datagen.flow(x_train, y_train, batch_size=32),\n\u001b[0;32m----> 2\u001b[0;31m           steps_per_epoch=len(x_train) / 32, epochs=10,verbose=2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuKo3JudL1O6"
      },
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CSDsu6oL2sq",
        "outputId": "b456f3f6-a1d5-4167-d95d-5b7e1677f1bf"
      },
      "source": [
        "vgg16_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9szEDVvhL4c9",
        "outputId": "0eb26de8-4b42-46e9-aebe-032cb4953c90"
      },
      "source": [
        "model = Sequential()\n",
        "for layer in vgg16_model.layers:\n",
        "    print(layer)\n",
        "    model.add(layer)\n",
        "\n",
        "for layer in model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "model.pop()\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f4c70170a58>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c70170898>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c70083860>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4c7007e4e0>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c7007e0b8>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700830f0>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4c7007fa20>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c70096978>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c70096160>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700820b8>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4c700a37b8>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700a3748>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c7009fa58>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700b24a8>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4c700b2358>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700ac4a8>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700b5f98>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c700466a0>\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4c70046eb8>\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f4c700b5978>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f4c7004f978>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f4c70053400>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f4c70053908>\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 134,272,835\n",
            "Trainable params: 12,291\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpl-AnbuMESO"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm6zcP8CMTS-",
        "outputId": "e1ee8a20-6b91-43e9-b700-ead0922a75f5"
      },
      "source": [
        "model.fit(datagen.flow(tempx_train, tempt_train, batch_size=32),validation_data=(tempx_test,tempt_test),\n",
        "          steps_per_epoch=len(tempx_train) / 32, epochs=10,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "130/130 [==============================] - 64s 484ms/step - loss: 1.0680 - accuracy: 0.4535 - val_loss: 1.0672 - val_accuracy: 0.4260\n",
            "Epoch 2/10\n",
            "130/130 [==============================] - 61s 464ms/step - loss: 0.9764 - accuracy: 0.5081 - val_loss: 1.0903 - val_accuracy: 0.4620\n",
            "Epoch 3/10\n",
            "130/130 [==============================] - 61s 464ms/step - loss: 0.9067 - accuracy: 0.5789 - val_loss: 1.1515 - val_accuracy: 0.4420\n",
            "Epoch 4/10\n",
            "130/130 [==============================] - 61s 469ms/step - loss: 0.8629 - accuracy: 0.6151 - val_loss: 1.1640 - val_accuracy: 0.4660\n",
            "Epoch 5/10\n",
            "130/130 [==============================] - 61s 466ms/step - loss: 0.8219 - accuracy: 0.6436 - val_loss: 1.2832 - val_accuracy: 0.4120\n",
            "Epoch 6/10\n",
            "130/130 [==============================] - 61s 464ms/step - loss: 0.7923 - accuracy: 0.6515 - val_loss: 1.2568 - val_accuracy: 0.4560\n",
            "Epoch 7/10\n",
            "130/130 [==============================] - 60s 462ms/step - loss: 0.7716 - accuracy: 0.6707 - val_loss: 1.3162 - val_accuracy: 0.4380\n",
            "Epoch 8/10\n",
            "130/130 [==============================] - 61s 466ms/step - loss: 0.7450 - accuracy: 0.6800 - val_loss: 1.3692 - val_accuracy: 0.4260\n",
            "Epoch 9/10\n",
            "130/130 [==============================] - 61s 466ms/step - loss: 0.7271 - accuracy: 0.6822 - val_loss: 1.3705 - val_accuracy: 0.4420\n",
            "Epoch 10/10\n",
            "130/130 [==============================] - 61s 464ms/step - loss: 0.7132 - accuracy: 0.6965 - val_loss: 1.3884 - val_accuracy: 0.4200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4c1f9a2fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}