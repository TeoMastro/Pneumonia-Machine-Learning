{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBtb10U3OPJ1",
        "outputId": "cc60e2b4-ab48-4b48-adb0-d2f62c9660ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13t7H0HBO77F",
        "outputId": "1fb4fbfc-b01e-4eb3-e227-f2e457f621d3"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Concatenate, \\\n",
        "                                    AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from numpy.linalg import inv, norm\n",
        "\n",
        "np.set_printoptions(suppress=True, precision=3)\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "print(os.getcwd())\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zPdgQ-3OoUF"
      },
      "source": [
        "train_labels = pd.read_csv('/content/gdrive/MyDrive/Xray dataset/labels_train.csv')\n",
        "test_labels = pd.read_csv('/content/gdrive/MyDrive/Xray dataset/sample_submission.csv')\n",
        "dataset_url = '/content/gdrive/MyDrive/Xray dataset'\n",
        "directory_train = '/content/gdrive/MyDrive/Xray dataset/train_images/'\n",
        "directory_test = '/content/gdrive/MyDrive/Xray dataset/test_images/'\n",
        "trainingNPY = '/content/gdrive/MyDrive/pneumonia/training.npy'\n",
        "testingNPY = '/content/gdrive/MyDrive/pneumonia/testing.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URLrlkm5Pe4M"
      },
      "source": [
        "x_train=np.load(trainingNPY)\n",
        "x_test=np.load(testingNPY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2-O-_TcPhkb"
      },
      "source": [
        "IMG_SIZE = 128\n",
        "x_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx5gXIExPizC"
      },
      "source": [
        "x_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOOPDhK3Plqm",
        "outputId": "881b6fb5-261f-4f95-e980-520c3e08f857"
      },
      "source": [
        "y_train = np.array(train_labels.drop(['file_name'],axis=1))\n",
        "y_train.shape\n",
        "print(y_train)\n",
        "y_test = np.array(test_labels.drop(['file_name'],axis=1))\n",
        "y_test.shape\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [2]\n",
            " [2]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rx-uck6Pol9",
        "outputId": "3d819bd0-583f-4109-c723-eac5bb8c8031"
      },
      "source": [
        "num_classes=3\n",
        "depth=20\n",
        "\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "t_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "t_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('y_train (labels) shape:', y_train.shape)\n",
        "print('t_train (one-hot rep) shape:', t_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train (labels) shape: (4672, 1)\n",
            "t_train (one-hot rep) shape: (4672, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LZaHPUAPus3"
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPyv-jstPx34"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=3):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=2, ### originally: 1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            \n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    print('Model parameters: {:d}'.format(model.count_params()))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__OzfgJAP03X"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX0XAUnrP3Vi"
      },
      "source": [
        "'''\n",
        "Epoch monitoring: Print info at every epoch\n",
        "'''\n",
        "\n",
        "class MyCallback(keras.callbacks.Callback):\n",
        "    tstart = None\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "    \n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.tstart = time.time()\n",
        "        print('epoch:{:03d}'.format(epoch+1), end=', ')\n",
        "        return\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print('loss:{:8.6f}, acc:{:8.6f},  val_loss:{:8.6f}, val_acc:{:8.6f},  val_acc-acc = {:5.2f}%,  lr:{:0.6f}  [{:0.2f} sec]'.format(\n",
        "                logs.get('loss'), logs.get('acc'),\n",
        "                logs.get('val_loss'), logs.get('val_acc'),\n",
        "                100*(logs.get('val_acc')-logs.get('acc')),\n",
        "                K.eval(self.model.optimizer.lr),\n",
        "                time.time()-self.tstart))\n",
        "        return\n",
        "    \n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "    \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rww_dwgVP5If",
        "outputId": "127f97dc-eddf-44a9-ff5d-d02e2ad11700"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "    \n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters: 284259\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 16) 160         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 16) 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 128, 128, 16) 0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 128, 128, 16) 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 16) 2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 16) 64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 16) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 16) 2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 16) 64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 128, 128, 16) 0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 16) 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 16) 2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 128, 128, 16) 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 128, 128, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 16) 2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128, 128, 16) 64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 128, 128, 16) 0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 128, 128, 16) 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 32)   4640        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 32)   2080        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 64, 32)   0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 64, 64, 32)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 64, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 64, 64, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 64, 64, 32)   0           activation_10[0][0]              \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 64, 64, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 64)   18496       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 64)   8256        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 64)   0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 64)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 64)   36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 64)   36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 64)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 64)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 64)   36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 32, 32, 64)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 64)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 3)            3075        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 284,259\n",
            "Trainable params: 282,883\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ua8wCgYP6Wp",
        "outputId": "4084b33b-b1e6-4810-bdcf-f2d1eff55cac"
      },
      "source": [
        "'''\n",
        "The Model object has the following attributes\n",
        "['_uses_inputs_arg', 'inputs', 'outputs', 'name', 'trainable',\n",
        "'_is_compiled', '_expects_training_arg', '_initial_weights', 'supports_masking', 'optimizer',\n",
        "'_updates', '_losses', '_per_input_losses', '_per_input_updates', '_layers',\n",
        "'_outbound_nodes', '_inbound_nodes', '_compute_previous_mask', '_built', '_is_graph_network',\n",
        "'_input_layers', '_output_layers', '_input_coordinates', '_output_coordinates', '_output_mask_cache',\n",
        "'_output_tensor_cache', '_output_shape_cache', '_network_nodes', '_nodes_by_depth', '_layers_by_depth',\n",
        "'input_names', 'output_names', '_feed_input_names', '_feed_inputs', '_feed_input_shapes',\n",
        "'loss', 'metrics', 'loss_weights', 'sample_weight_mode', 'weighted_metrics',\n",
        "'loss_functions', '_feed_outputs', '_feed_output_names', '_feed_output_shapes', '_feed_loss_fns',\n",
        "'targets', '_feed_targets', 'sample_weight_modes', '_feed_sample_weight_modes', 'metrics_names',\n",
        "'metrics_tensors', 'metrics_updates', 'stateful_metric_names', 'stateful_metric_functions', 'total_loss',\n",
        "'sample_weights', '_feed_sample_weights', '_function_kwargs', 'train_function', 'test_function',\n",
        "'predict_function', '_collected_trainable_weights', 'history', 'stop_training'])\n",
        "'''\n",
        "for layer in range(len(model._layers)):\n",
        "    layer_obj = model._layers[layer]\n",
        "    print('{}'.format(layer_obj.name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1\n",
            "conv2d\n",
            "batch_normalization\n",
            "activation\n",
            "conv2d_1\n",
            "batch_normalization_1\n",
            "activation_1\n",
            "conv2d_2\n",
            "batch_normalization_2\n",
            "add\n",
            "activation_2\n",
            "conv2d_3\n",
            "batch_normalization_3\n",
            "activation_3\n",
            "conv2d_4\n",
            "batch_normalization_4\n",
            "add_1\n",
            "activation_4\n",
            "conv2d_5\n",
            "batch_normalization_5\n",
            "activation_5\n",
            "conv2d_6\n",
            "batch_normalization_6\n",
            "add_2\n",
            "activation_6\n",
            "conv2d_7\n",
            "batch_normalization_7\n",
            "activation_7\n",
            "conv2d_8\n",
            "conv2d_9\n",
            "batch_normalization_8\n",
            "add_3\n",
            "activation_8\n",
            "conv2d_10\n",
            "batch_normalization_9\n",
            "activation_9\n",
            "conv2d_11\n",
            "batch_normalization_10\n",
            "add_4\n",
            "activation_10\n",
            "conv2d_12\n",
            "batch_normalization_11\n",
            "activation_11\n",
            "conv2d_13\n",
            "batch_normalization_12\n",
            "add_5\n",
            "activation_12\n",
            "conv2d_14\n",
            "batch_normalization_13\n",
            "activation_13\n",
            "conv2d_15\n",
            "conv2d_16\n",
            "batch_normalization_14\n",
            "add_6\n",
            "activation_14\n",
            "conv2d_17\n",
            "batch_normalization_15\n",
            "activation_15\n",
            "conv2d_18\n",
            "batch_normalization_16\n",
            "add_7\n",
            "activation_16\n",
            "conv2d_19\n",
            "batch_normalization_17\n",
            "activation_17\n",
            "conv2d_20\n",
            "batch_normalization_18\n",
            "add_8\n",
            "activation_18\n",
            "average_pooling2d\n",
            "flatten\n",
            "dense\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs8w34QVP9ZM",
        "outputId": "f069c373-996f-4887-b8f6-aae099dd0d54"
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
        "epochs = 200\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "model_name = 'resnet20-e{epoch:04d}-loss{loss:.3f}-acc{acc:.3f}-valloss{val_loss:.3f}-valacc{val_acc:.3f}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    # set input mean to 0 over the dataset\n",
        "    featurewise_center=False,\n",
        "    # set each sample mean to 0\n",
        "    samplewise_center=False,\n",
        "    # divide inputs by std of dataset\n",
        "    featurewise_std_normalization=False,\n",
        "    # divide each input by its std\n",
        "    samplewise_std_normalization=False,\n",
        "    # apply ZCA whitening\n",
        "    zca_whitening=False,\n",
        "    # epsilon for ZCA whitening\n",
        "    zca_epsilon=1e-06,\n",
        "    # randomly rotate images in the range (deg 0 to 180)\n",
        "    rotation_range=0,\n",
        "    # randomly shift images horizontally\n",
        "    width_shift_range=0.1,\n",
        "    # randomly shift images vertically\n",
        "    height_shift_range=0.1,\n",
        "    # set range for random shear\n",
        "    shear_range=0.,\n",
        "    # set range for random zoom\n",
        "    zoom_range=0.,\n",
        "    # set range for random channel shifts\n",
        "    channel_shift_range=0.,\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    # value used for fill_mode = \"constant\"\n",
        "    cval=0.,\n",
        "    # randomly flip images\n",
        "    horizontal_flip=True,\n",
        "    # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None,\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "    validation_split=0.0)\n",
        "\n",
        "# Compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "history = model.fit(datagen.flow(x_train, t_train, batch_size=batch_size),\n",
        "                                validation_data=(x_test, t_test),\n",
        "                                epochs=epochs, verbose=0, workers=4,\n",
        "                                steps_per_epoch = int(x_train.shape[0]/batch_size),\n",
        "                                callbacks=[lr_reducer, lr_scheduler, MyCallback(), checkpoint])\n",
        "\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, t_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:001, WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0812s vs `on_train_batch_end` time: 0.0952s). Check your callbacks.\n",
            "loss:0.929248, acc:0.672089,  val_loss:2.561353, val_acc:0.311644,  val_acc-acc = -36.04%,  lr:0.001000  [40.80 sec]\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.31164, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0001-loss0.929-acc0.672-valloss2.561-valacc0.312.h5\n",
            "epoch:002, loss:0.738686, acc:0.747217,  val_loss:2.290687, val_acc:0.313356,  val_acc-acc = -43.39%,  lr:0.001000  [30.75 sec]\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.31164 to 0.31336, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0002-loss0.739-acc0.747-valloss2.291-valacc0.313.h5\n",
            "epoch:003, loss:0.724560, acc:0.761986,  val_loss:2.450344, val_acc:0.343322,  val_acc-acc = -41.87%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.31336 to 0.34332, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0003-loss0.725-acc0.762-valloss2.450-valacc0.343.h5\n",
            "epoch:004, loss:0.700835, acc:0.769264,  val_loss:2.476183, val_acc:0.340753,  val_acc-acc = -42.85%,  lr:0.001000  [31.24 sec]\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.34332\n",
            "epoch:005, loss:0.678477, acc:0.771832,  val_loss:2.782834, val_acc:0.340753,  val_acc-acc = -43.11%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.34332\n",
            "epoch:006, loss:0.658692, acc:0.781464,  val_loss:3.068385, val_acc:0.307363,  val_acc-acc = -47.41%,  lr:0.001000  [31.06 sec]\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.34332\n",
            "epoch:007, loss:0.655454, acc:0.782748,  val_loss:2.959849, val_acc:0.321918,  val_acc-acc = -46.08%,  lr:0.000316  [31.11 sec]\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.34332\n",
            "epoch:008, loss:0.636154, acc:0.784247,  val_loss:4.026012, val_acc:0.303082,  val_acc-acc = -48.12%,  lr:0.001000  [31.10 sec]\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.34332\n",
            "epoch:009, loss:0.641503, acc:0.784033,  val_loss:3.566649, val_acc:0.314212,  val_acc-acc = -46.98%,  lr:0.001000  [31.12 sec]\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.34332\n",
            "epoch:010, loss:0.625745, acc:0.798373,  val_loss:2.874631, val_acc:0.335616,  val_acc-acc = -46.28%,  lr:0.001000  [31.04 sec]\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.34332\n",
            "epoch:011, loss:0.616527, acc:0.791096,  val_loss:3.699379, val_acc:0.323630,  val_acc-acc = -46.75%,  lr:0.001000  [31.13 sec]\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.34332\n",
            "epoch:012, loss:0.605731, acc:0.801584,  val_loss:3.062048, val_acc:0.330479,  val_acc-acc = -47.11%,  lr:0.000316  [31.14 sec]\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.34332\n",
            "epoch:013, loss:0.613043, acc:0.792166,  val_loss:3.098479, val_acc:0.310788,  val_acc-acc = -48.14%,  lr:0.001000  [31.12 sec]\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.34332\n",
            "epoch:014, loss:0.590347, acc:0.799229,  val_loss:3.657875, val_acc:0.317637,  val_acc-acc = -48.16%,  lr:0.001000  [31.07 sec]\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.34332\n",
            "epoch:015, loss:0.602120, acc:0.797089,  val_loss:3.022597, val_acc:0.344178,  val_acc-acc = -45.29%,  lr:0.001000  [31.10 sec]\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.34332 to 0.34418, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0015-loss0.602-acc0.797-valloss3.023-valacc0.344.h5\n",
            "epoch:016, loss:0.573962, acc:0.808219,  val_loss:4.050857, val_acc:0.315925,  val_acc-acc = -49.23%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.34418\n",
            "epoch:017, loss:0.571848, acc:0.806079,  val_loss:2.741359, val_acc:0.340753,  val_acc-acc = -46.53%,  lr:0.000316  [31.11 sec]\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.34418\n",
            "epoch:018, loss:0.564538, acc:0.815711,  val_loss:3.111254, val_acc:0.331336,  val_acc-acc = -48.44%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.34418\n",
            "epoch:019, loss:0.563599, acc:0.805865,  val_loss:3.050714, val_acc:0.334760,  val_acc-acc = -47.11%,  lr:0.001000  [31.07 sec]\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.34418\n",
            "epoch:020, loss:0.543648, acc:0.813142,  val_loss:3.376259, val_acc:0.328767,  val_acc-acc = -48.44%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.34418\n",
            "epoch:021, loss:0.546262, acc:0.815068,  val_loss:2.910883, val_acc:0.332192,  val_acc-acc = -48.29%,  lr:0.001000  [31.10 sec]\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.34418\n",
            "epoch:022, loss:0.539438, acc:0.819563,  val_loss:3.219372, val_acc:0.327911,  val_acc-acc = -49.17%,  lr:0.000316  [31.09 sec]\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.34418\n",
            "epoch:023, loss:0.548470, acc:0.809075,  val_loss:3.649958, val_acc:0.333048,  val_acc-acc = -47.60%,  lr:0.001000  [31.06 sec]\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.34418\n",
            "epoch:024, loss:0.538633, acc:0.812072,  val_loss:3.341935, val_acc:0.314212,  val_acc-acc = -49.79%,  lr:0.001000  [31.10 sec]\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.34418\n",
            "epoch:025, loss:0.524718, acc:0.816353,  val_loss:3.495664, val_acc:0.350171,  val_acc-acc = -46.62%,  lr:0.001000  [31.10 sec]\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.34418 to 0.35017, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0025-loss0.525-acc0.816-valloss3.496-valacc0.350.h5\n",
            "epoch:026, loss:0.531770, acc:0.818493,  val_loss:3.218256, val_acc:0.312500,  val_acc-acc = -50.60%,  lr:0.001000  [31.15 sec]\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.35017\n",
            "epoch:027, loss:0.524500, acc:0.817637,  val_loss:3.775326, val_acc:0.313356,  val_acc-acc = -50.43%,  lr:0.000316  [31.16 sec]\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.35017\n",
            "epoch:028, loss:0.521633, acc:0.822988,  val_loss:3.624054, val_acc:0.320205,  val_acc-acc = -50.28%,  lr:0.001000  [31.15 sec]\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.35017\n",
            "epoch:029, loss:0.518212, acc:0.819563,  val_loss:2.845965, val_acc:0.334760,  val_acc-acc = -48.48%,  lr:0.001000  [31.14 sec]\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.35017\n",
            "epoch:030, loss:0.514046, acc:0.821918,  val_loss:3.771346, val_acc:0.317637,  val_acc-acc = -50.43%,  lr:0.001000  [31.17 sec]\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.35017\n",
            "epoch:031, loss:0.504665, acc:0.827269,  val_loss:3.180927, val_acc:0.343322,  val_acc-acc = -48.39%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.35017\n",
            "epoch:032, loss:0.496468, acc:0.832192,  val_loss:4.423935, val_acc:0.317637,  val_acc-acc = -51.46%,  lr:0.000316  [31.09 sec]\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.35017\n",
            "epoch:033, loss:0.500065, acc:0.828981,  val_loss:4.272378, val_acc:0.330479,  val_acc-acc = -49.85%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.35017\n",
            "epoch:034, loss:0.496348, acc:0.822346,  val_loss:3.513195, val_acc:0.329623,  val_acc-acc = -49.27%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.35017\n",
            "epoch:035, loss:0.502005, acc:0.826627,  val_loss:4.732172, val_acc:0.319349,  val_acc-acc = -50.73%,  lr:0.001000  [30.93 sec]\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.35017\n",
            "epoch:036, loss:0.487427, acc:0.834546,  val_loss:3.522570, val_acc:0.359589,  val_acc-acc = -47.50%,  lr:0.001000  [31.02 sec]\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.35017 to 0.35959, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0036-loss0.487-acc0.835-valloss3.523-valacc0.360.h5\n",
            "epoch:037, loss:0.491868, acc:0.832620,  val_loss:3.991750, val_acc:0.321918,  val_acc-acc = -51.07%,  lr:0.000316  [31.08 sec]\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.35959\n",
            "epoch:038, loss:0.487197, acc:0.830693,  val_loss:3.781825, val_acc:0.329623,  val_acc-acc = -50.11%,  lr:0.001000  [31.25 sec]\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.35959\n",
            "epoch:039, loss:0.490051, acc:0.834546,  val_loss:4.033548, val_acc:0.323630,  val_acc-acc = -51.09%,  lr:0.001000  [31.20 sec]\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.35959\n",
            "epoch:040, loss:0.476785, acc:0.835188,  val_loss:3.683026, val_acc:0.327055,  val_acc-acc = -50.81%,  lr:0.001000  [31.19 sec]\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.35959\n",
            "epoch:041, loss:0.473275, acc:0.842252,  val_loss:3.177911, val_acc:0.339041,  val_acc-acc = -50.32%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.35959\n",
            "epoch:042, loss:0.480659, acc:0.834546,  val_loss:4.092753, val_acc:0.325342,  val_acc-acc = -50.92%,  lr:0.000316  [31.13 sec]\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.35959\n",
            "epoch:043, loss:0.476014, acc:0.839469,  val_loss:3.494930, val_acc:0.323630,  val_acc-acc = -51.58%,  lr:0.001000  [31.28 sec]\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.35959\n",
            "epoch:044, loss:0.466609, acc:0.842894,  val_loss:3.734213, val_acc:0.321062,  val_acc-acc = -52.18%,  lr:0.001000  [31.19 sec]\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.35959\n",
            "epoch:045, loss:0.465530, acc:0.846104,  val_loss:3.787424, val_acc:0.321918,  val_acc-acc = -52.42%,  lr:0.001000  [31.16 sec]\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.35959\n",
            "epoch:046, loss:0.458319, acc:0.844606,  val_loss:3.422369, val_acc:0.337329,  val_acc-acc = -50.73%,  lr:0.001000  [30.93 sec]\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.35959\n",
            "epoch:047, loss:0.459602, acc:0.844178,  val_loss:3.835318, val_acc:0.313356,  val_acc-acc = -53.08%,  lr:0.000316  [31.04 sec]\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.35959\n",
            "epoch:048, loss:0.465140, acc:0.846533,  val_loss:3.822995, val_acc:0.324486,  val_acc-acc = -52.20%,  lr:0.001000  [31.11 sec]\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.35959\n",
            "epoch:049, loss:0.451934, acc:0.846318,  val_loss:3.863126, val_acc:0.314212,  val_acc-acc = -53.21%,  lr:0.001000  [31.03 sec]\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.35959\n",
            "epoch:050, loss:0.453100, acc:0.841610,  val_loss:4.264808, val_acc:0.320205,  val_acc-acc = -52.14%,  lr:0.001000  [31.23 sec]\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.35959\n",
            "epoch:051, loss:0.434253, acc:0.854880,  val_loss:4.413897, val_acc:0.305651,  val_acc-acc = -54.92%,  lr:0.001000  [31.06 sec]\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.35959\n",
            "epoch:052, loss:0.438458, acc:0.853382,  val_loss:3.317686, val_acc:0.327911,  val_acc-acc = -52.55%,  lr:0.000316  [31.03 sec]\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.35959\n",
            "epoch:053, loss:0.436865, acc:0.855094,  val_loss:4.491426, val_acc:0.326199,  val_acc-acc = -52.89%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.35959\n",
            "epoch:054, loss:0.456279, acc:0.855950,  val_loss:4.081810, val_acc:0.311644,  val_acc-acc = -54.43%,  lr:0.001000  [31.02 sec]\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.35959\n",
            "epoch:055, loss:0.427100, acc:0.861943,  val_loss:3.472889, val_acc:0.325342,  val_acc-acc = -53.66%,  lr:0.001000  [30.99 sec]\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.35959\n",
            "epoch:056, loss:0.438742, acc:0.851670,  val_loss:4.169257, val_acc:0.316781,  val_acc-acc = -53.49%,  lr:0.001000  [30.94 sec]\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.35959\n",
            "epoch:057, loss:0.435313, acc:0.857663,  val_loss:4.582460, val_acc:0.309075,  val_acc-acc = -54.86%,  lr:0.000316  [31.05 sec]\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.35959\n",
            "epoch:058, loss:0.417803, acc:0.867295,  val_loss:4.065079, val_acc:0.320205,  val_acc-acc = -54.71%,  lr:0.001000  [31.07 sec]\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.35959\n",
            "epoch:059, loss:0.421941, acc:0.863014,  val_loss:4.197798, val_acc:0.335616,  val_acc-acc = -52.74%,  lr:0.001000  [31.09 sec]\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.35959\n",
            "epoch:060, loss:0.419950, acc:0.862586,  val_loss:4.859587, val_acc:0.323630,  val_acc-acc = -53.90%,  lr:0.001000  [31.08 sec]\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.35959\n",
            "epoch:061, loss:0.428073, acc:0.855308,  val_loss:4.071815, val_acc:0.318493,  val_acc-acc = -53.68%,  lr:0.001000  [30.99 sec]\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.35959\n",
            "epoch:062, loss:0.404847, acc:0.869649,  val_loss:4.317758, val_acc:0.330479,  val_acc-acc = -53.92%,  lr:0.000316  [31.14 sec]\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.35959\n",
            "epoch:063, loss:0.436701, acc:0.858519,  val_loss:4.157715, val_acc:0.364726,  val_acc-acc = -49.38%,  lr:0.001000  [31.00 sec]\n",
            "\n",
            "Epoch 00063: val_acc improved from 0.35959 to 0.36473, saving model to /content/gdrive/My Drive/Colab Notebooks/saved_models/resnet20-e0063-loss0.437-acc0.859-valloss4.158-valacc0.365.h5\n",
            "epoch:064, loss:0.400784, acc:0.873074,  val_loss:4.928786, val_acc:0.327055,  val_acc-acc = -54.60%,  lr:0.001000  [31.13 sec]\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.36473\n",
            "epoch:065, loss:0.418571, acc:0.869221,  val_loss:5.239277, val_acc:0.324486,  val_acc-acc = -54.47%,  lr:0.001000  [31.13 sec]\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.36473\n",
            "epoch:066, loss:0.410032, acc:0.872432,  val_loss:4.590122, val_acc:0.298801,  val_acc-acc = -57.36%,  lr:0.001000  [31.02 sec]\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.36473\n",
            "epoch:067, loss:0.409508, acc:0.870291,  val_loss:4.043366, val_acc:0.334760,  val_acc-acc = -53.55%,  lr:0.000316  [31.03 sec]\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.36473\n",
            "epoch:068, loss:0.395386, acc:0.878639,  val_loss:5.967997, val_acc:0.313356,  val_acc-acc = -56.53%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.36473\n",
            "epoch:069, loss:0.382760, acc:0.887200,  val_loss:5.475842, val_acc:0.317637,  val_acc-acc = -56.96%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.36473\n",
            "epoch:070, loss:0.385468, acc:0.883990,  val_loss:5.029648, val_acc:0.326199,  val_acc-acc = -55.78%,  lr:0.001000  [31.07 sec]\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.36473\n",
            "epoch:071, loss:0.408268, acc:0.875214,  val_loss:4.653078, val_acc:0.327911,  val_acc-acc = -54.73%,  lr:0.001000  [31.08 sec]\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.36473\n",
            "epoch:072, loss:0.405394, acc:0.878639,  val_loss:4.622041, val_acc:0.313356,  val_acc-acc = -56.53%,  lr:0.000316  [31.03 sec]\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.36473\n",
            "epoch:073, loss:0.392747, acc:0.885274,  val_loss:4.359999, val_acc:0.351884,  val_acc-acc = -53.34%,  lr:0.001000  [31.05 sec]\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.36473\n",
            "epoch:074, loss:0.376941, acc:0.888913,  val_loss:4.102044, val_acc:0.348459,  val_acc-acc = -54.05%,  lr:0.001000  [30.78 sec]\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.36473\n",
            "epoch:075, loss:0.386366, acc:0.891267,  val_loss:6.202784, val_acc:0.321062,  val_acc-acc = -57.02%,  lr:0.001000  [30.85 sec]\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.36473\n",
            "epoch:076, loss:0.370570, acc:0.888271,  val_loss:6.508928, val_acc:0.320205,  val_acc-acc = -56.81%,  lr:0.001000  [30.92 sec]\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.36473\n",
            "epoch:077, loss:0.369628, acc:0.892337,  val_loss:6.232198, val_acc:0.292808,  val_acc-acc = -59.95%,  lr:0.000316  [30.90 sec]\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.36473\n",
            "epoch:078, loss:0.382115, acc:0.887200,  val_loss:5.149225, val_acc:0.321918,  val_acc-acc = -56.53%,  lr:0.001000  [31.10 sec]\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.36473\n",
            "epoch:079, loss:0.368458, acc:0.897046,  val_loss:5.756012, val_acc:0.321918,  val_acc-acc = -57.51%,  lr:0.001000  [31.06 sec]\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.36473\n",
            "epoch:080, loss:0.372694, acc:0.889555,  val_loss:5.325267, val_acc:0.325342,  val_acc-acc = -56.42%,  lr:0.001000  [31.09 sec]\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.36473\n",
            "epoch:081, loss:0.360564, acc:0.898545,  val_loss:4.668483, val_acc:0.328767,  val_acc-acc = -56.98%,  lr:0.001000  [31.06 sec]\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.36473\n",
            "epoch:082, loss:0.311478, acc:0.921447,  val_loss:5.592461, val_acc:0.322774,  val_acc-acc = -59.87%,  lr:0.000032  [31.21 sec]\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.36473\n",
            "epoch:083, loss:0.287744, acc:0.935788,  val_loss:5.683048, val_acc:0.320205,  val_acc-acc = -61.56%,  lr:0.000100  [31.18 sec]\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.36473\n",
            "epoch:084, loss:0.271349, acc:0.942209,  val_loss:5.641623, val_acc:0.322774,  val_acc-acc = -61.94%,  lr:0.000100  [31.08 sec]\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.36473\n",
            "epoch:085, loss:0.267356, acc:0.943279,  val_loss:5.891497, val_acc:0.322774,  val_acc-acc = -62.05%,  lr:0.000100  [31.04 sec]\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.36473\n",
            "epoch:086, loss:0.263828, acc:0.941353,  val_loss:5.994175, val_acc:0.323630,  val_acc-acc = -61.77%,  lr:0.000100  [31.05 sec]\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.36473\n",
            "epoch:087, loss:0.254807, acc:0.946276,  val_loss:6.057020, val_acc:0.323630,  val_acc-acc = -62.26%,  lr:0.000032  [31.19 sec]\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.36473\n",
            "epoch:088, loss:0.243590, acc:0.949914,  val_loss:5.936559, val_acc:0.326199,  val_acc-acc = -62.37%,  lr:0.000100  [31.20 sec]\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.36473\n",
            "epoch:089, loss:0.242798, acc:0.950771,  val_loss:6.376395, val_acc:0.317637,  val_acc-acc = -63.31%,  lr:0.000100  [31.12 sec]\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.36473\n",
            "epoch:090, loss:0.240002, acc:0.958048,  val_loss:6.374294, val_acc:0.321062,  val_acc-acc = -63.70%,  lr:0.000100  [31.10 sec]\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.36473\n",
            "epoch:091, loss:0.236782, acc:0.956550,  val_loss:6.304886, val_acc:0.319349,  val_acc-acc = -63.72%,  lr:0.000100  [31.25 sec]\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.36473\n",
            "epoch:092, loss:0.228765, acc:0.958476,  val_loss:6.204123, val_acc:0.325342,  val_acc-acc = -63.31%,  lr:0.000032  [31.11 sec]\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.36473\n",
            "epoch:093, loss:0.227570, acc:0.959332,  val_loss:6.506867, val_acc:0.321918,  val_acc-acc = -63.74%,  lr:0.000100  [31.11 sec]\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.36473\n",
            "epoch:094, loss:0.227600, acc:0.955908,  val_loss:6.432565, val_acc:0.321062,  val_acc-acc = -63.48%,  lr:0.000100  [31.10 sec]\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.36473\n",
            "epoch:095, loss:0.216439, acc:0.963613,  val_loss:6.426415, val_acc:0.329623,  val_acc-acc = -63.40%,  lr:0.000100  [31.10 sec]\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.36473\n",
            "epoch:096, loss:0.210302, acc:0.967680,  val_loss:6.328520, val_acc:0.322774,  val_acc-acc = -64.49%,  lr:0.000100  [31.06 sec]\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.36473\n",
            "epoch:097, loss:0.213413, acc:0.962543,  val_loss:6.858326, val_acc:0.327055,  val_acc-acc = -63.55%,  lr:0.000032  [31.11 sec]\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.36473\n",
            "epoch:098, loss:0.206977, acc:0.968536,  val_loss:6.663006, val_acc:0.327911,  val_acc-acc = -64.06%,  lr:0.000100  [31.16 sec]\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.36473\n",
            "epoch:099, loss:0.203528, acc:0.968322,  val_loss:6.849227, val_acc:0.323630,  val_acc-acc = -64.47%,  lr:0.000100  [31.09 sec]\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.36473\n",
            "epoch:100, loss:0.208262, acc:0.965753,  val_loss:6.505075, val_acc:0.323630,  val_acc-acc = -64.21%,  lr:0.000100  [31.08 sec]\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.36473\n",
            "epoch:101, loss:0.199101, acc:0.970248,  val_loss:6.377621, val_acc:0.324486,  val_acc-acc = -64.58%,  lr:0.000100  [31.14 sec]\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.36473\n",
            "epoch:102, loss:0.198832, acc:0.970462,  val_loss:6.966051, val_acc:0.319349,  val_acc-acc = -65.11%,  lr:0.000032  [31.13 sec]\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.36473\n",
            "epoch:103, loss:0.192472, acc:0.970890,  val_loss:6.986418, val_acc:0.321918,  val_acc-acc = -64.90%,  lr:0.000100  [31.11 sec]\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.36473\n",
            "epoch:104, loss:0.195926, acc:0.970034,  val_loss:6.702055, val_acc:0.325342,  val_acc-acc = -64.47%,  lr:0.000100  [31.05 sec]\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.36473\n",
            "epoch:105, loss:0.196391, acc:0.968108,  val_loss:7.073461, val_acc:0.324486,  val_acc-acc = -64.36%,  lr:0.000100  [31.13 sec]\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.36473\n",
            "epoch:106, loss:0.190358, acc:0.971747,  val_loss:7.303404, val_acc:0.327055,  val_acc-acc = -64.47%,  lr:0.000100  [31.12 sec]\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.36473\n",
            "epoch:107, loss:0.186749, acc:0.974315,  val_loss:6.738471, val_acc:0.327055,  val_acc-acc = -64.73%,  lr:0.000032  [31.10 sec]\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.36473\n",
            "epoch:108, loss:0.186847, acc:0.974529,  val_loss:7.008897, val_acc:0.325342,  val_acc-acc = -64.92%,  lr:0.000100  [31.14 sec]\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.36473\n",
            "epoch:109, loss:0.181618, acc:0.972817,  val_loss:7.077796, val_acc:0.319349,  val_acc-acc = -65.35%,  lr:0.000100  [31.12 sec]\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.36473\n",
            "epoch:110, loss:0.182735, acc:0.975813,  val_loss:7.083951, val_acc:0.322774,  val_acc-acc = -65.30%,  lr:0.000100  [31.10 sec]\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.36473\n",
            "epoch:111, loss:0.176749, acc:0.977954,  val_loss:6.964460, val_acc:0.322774,  val_acc-acc = -65.52%,  lr:0.000100  [31.05 sec]\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.36473\n",
            "epoch:112, loss:0.174628, acc:0.976884,  val_loss:7.573004, val_acc:0.323630,  val_acc-acc = -65.33%,  lr:0.000032  [31.10 sec]\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.36473\n",
            "epoch:113, loss:0.176727, acc:0.977098,  val_loss:7.466429, val_acc:0.327911,  val_acc-acc = -64.92%,  lr:0.000100  [31.11 sec]\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.36473\n",
            "epoch:114, loss:0.173273, acc:0.980308,  val_loss:7.284751, val_acc:0.321918,  val_acc-acc = -65.84%,  lr:0.000100  [31.14 sec]\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.36473\n",
            "epoch:115, loss:0.172238, acc:0.977098,  val_loss:7.463695, val_acc:0.327055,  val_acc-acc = -65.00%,  lr:0.000100  [31.07 sec]\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.36473\n",
            "epoch:116, loss:0.167461, acc:0.980308,  val_loss:7.185322, val_acc:0.332192,  val_acc-acc = -64.81%,  lr:0.000100  [31.13 sec]\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.36473\n",
            "epoch:117, loss:0.168500, acc:0.978810,  val_loss:7.542345, val_acc:0.324486,  val_acc-acc = -65.43%,  lr:0.000032  [31.17 sec]\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.36473\n",
            "epoch:118, loss:0.162830, acc:0.981164,  val_loss:7.654385, val_acc:0.321918,  val_acc-acc = -65.92%,  lr:0.000100  [31.17 sec]\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.36473\n",
            "epoch:119, loss:0.163123, acc:0.982021,  val_loss:7.200248, val_acc:0.325342,  val_acc-acc = -65.67%,  lr:0.000100  [31.13 sec]\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.36473\n",
            "epoch:120, loss:0.168409, acc:0.976455,  val_loss:7.259879, val_acc:0.325342,  val_acc-acc = -65.11%,  lr:0.000100  [31.03 sec]\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.36473\n",
            "epoch:121, loss:0.161367, acc:0.982449,  val_loss:7.690858, val_acc:0.322774,  val_acc-acc = -65.97%,  lr:0.000100  [31.04 sec]\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.36473\n",
            "epoch:122, loss:0.162184, acc:0.980950,  val_loss:7.649208, val_acc:0.321918,  val_acc-acc = -65.90%,  lr:0.000003  [31.10 sec]\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.36473\n",
            "epoch:123, loss:0.153271, acc:0.985231,  val_loss:7.692895, val_acc:0.321062,  val_acc-acc = -66.42%,  lr:0.000010  [31.04 sec]\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.36473\n",
            "epoch:124, loss:0.155062, acc:0.984375,  val_loss:7.692912, val_acc:0.319349,  val_acc-acc = -66.50%,  lr:0.000010  [30.92 sec]\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.36473\n",
            "epoch:125, loss:0.151256, acc:0.985873,  val_loss:7.655564, val_acc:0.319349,  val_acc-acc = -66.65%,  lr:0.000010  [31.08 sec]\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.36473\n",
            "epoch:126, loss:0.153389, acc:0.985231,  val_loss:7.658011, val_acc:0.320205,  val_acc-acc = -66.50%,  lr:0.000010  [31.17 sec]\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.36473\n",
            "epoch:127, loss:0.151195, acc:0.984589,  val_loss:7.685792, val_acc:0.319349,  val_acc-acc = -66.52%,  lr:0.000003  [31.13 sec]\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.36473\n",
            "epoch:128, loss:0.151090, acc:0.988228,  val_loss:7.669120, val_acc:0.321062,  val_acc-acc = -66.72%,  lr:0.000010  [31.11 sec]\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.36473\n",
            "epoch:129, loss:0.153218, acc:0.983947,  val_loss:7.639555, val_acc:0.321062,  val_acc-acc = -66.29%,  lr:0.000010  [31.11 sec]\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.36473\n",
            "epoch:130, loss:0.147408, acc:0.990582,  val_loss:7.652856, val_acc:0.322774,  val_acc-acc = -66.78%,  lr:0.000010  [31.16 sec]\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.36473\n",
            "epoch:131, loss:0.151567, acc:0.986301,  val_loss:7.663704, val_acc:0.321918,  val_acc-acc = -66.44%,  lr:0.000010  [31.13 sec]\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.36473\n",
            "epoch:132, loss:0.151842, acc:0.985445,  val_loss:7.688167, val_acc:0.321918,  val_acc-acc = -66.35%,  lr:0.000003  [31.09 sec]\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.36473\n",
            "epoch:133, loss:0.149649, acc:0.989298,  val_loss:7.684585, val_acc:0.323630,  val_acc-acc = -66.57%,  lr:0.000010  [31.12 sec]\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.36473\n",
            "epoch:134, loss:0.150855, acc:0.985873,  val_loss:7.674648, val_acc:0.323630,  val_acc-acc = -66.22%,  lr:0.000010  [31.12 sec]\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.36473\n",
            "epoch:135, loss:0.150885, acc:0.986943,  val_loss:7.682281, val_acc:0.326199,  val_acc-acc = -66.07%,  lr:0.000010  [31.02 sec]\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.36473\n",
            "epoch:136, loss:0.149152, acc:0.988870,  val_loss:7.690974, val_acc:0.324486,  val_acc-acc = -66.44%,  lr:0.000010  [31.04 sec]\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.36473\n",
            "epoch:137, loss:0.156529, acc:0.982449,  val_loss:7.707301, val_acc:0.323630,  val_acc-acc = -65.88%,  lr:0.000003  [31.04 sec]\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.36473\n",
            "epoch:138, loss:0.146928, acc:0.987586,  val_loss:7.658754, val_acc:0.324486,  val_acc-acc = -66.31%,  lr:0.000010  [31.02 sec]\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.36473\n",
            "epoch:139, loss:0.145610, acc:0.990368,  val_loss:7.732602, val_acc:0.324486,  val_acc-acc = -66.59%,  lr:0.000010  [31.04 sec]\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.36473\n",
            "epoch:140, loss:0.152268, acc:0.986943,  val_loss:7.720215, val_acc:0.325342,  val_acc-acc = -66.16%,  lr:0.000010  [31.03 sec]\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.36473\n",
            "epoch:141, loss:0.150783, acc:0.987586,  val_loss:7.726700, val_acc:0.322774,  val_acc-acc = -66.48%,  lr:0.000010  [31.09 sec]\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.36473\n",
            "epoch:142, loss:0.147685, acc:0.987372,  val_loss:7.760272, val_acc:0.321918,  val_acc-acc = -66.55%,  lr:0.000003  [31.04 sec]\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.36473\n",
            "epoch:143, loss:0.147531, acc:0.986729,  val_loss:7.728477, val_acc:0.324486,  val_acc-acc = -66.22%,  lr:0.000010  [31.21 sec]\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.36473\n",
            "epoch:144, loss:0.147029, acc:0.986943,  val_loss:7.690053, val_acc:0.322774,  val_acc-acc = -66.42%,  lr:0.000010  [31.10 sec]\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.36473\n",
            "epoch:145, loss:0.150032, acc:0.986515,  val_loss:7.681424, val_acc:0.325342,  val_acc-acc = -66.12%,  lr:0.000010  [31.10 sec]\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.36473\n",
            "epoch:146, loss:0.148169, acc:0.984803,  val_loss:7.688119, val_acc:0.323630,  val_acc-acc = -66.12%,  lr:0.000010  [31.08 sec]\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.36473\n",
            "epoch:147, loss:0.149239, acc:0.988014,  val_loss:7.745455, val_acc:0.325342,  val_acc-acc = -66.27%,  lr:0.000003  [31.14 sec]\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.36473\n",
            "epoch:148, loss:0.145466, acc:0.987586,  val_loss:7.783557, val_acc:0.326199,  val_acc-acc = -66.14%,  lr:0.000010  [31.13 sec]\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.36473\n",
            "epoch:149, loss:0.149750, acc:0.986515,  val_loss:7.690747, val_acc:0.323630,  val_acc-acc = -66.29%,  lr:0.000010  [31.18 sec]\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.36473\n",
            "epoch:150, loss:0.144385, acc:0.988656,  val_loss:7.735875, val_acc:0.325342,  val_acc-acc = -66.33%,  lr:0.000010  [31.06 sec]\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.36473\n",
            "epoch:151, loss:0.146939, acc:0.988442,  val_loss:7.740878, val_acc:0.324486,  val_acc-acc = -66.40%,  lr:0.000010  [31.07 sec]\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.36473\n",
            "epoch:152, loss:0.141808, acc:0.989726,  val_loss:7.733950, val_acc:0.323630,  val_acc-acc = -66.61%,  lr:0.000003  [31.19 sec]\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.36473\n",
            "epoch:153, loss:0.144796, acc:0.987800,  val_loss:7.762094, val_acc:0.323630,  val_acc-acc = -66.42%,  lr:0.000010  [31.21 sec]\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.36473\n",
            "epoch:154, loss:0.144829, acc:0.988442,  val_loss:7.814468, val_acc:0.327055,  val_acc-acc = -66.14%,  lr:0.000010  [31.19 sec]\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.36473\n",
            "epoch:155, loss:0.146869, acc:0.989084,  val_loss:7.823675, val_acc:0.326199,  val_acc-acc = -66.29%,  lr:0.000010  [31.18 sec]\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.36473\n",
            "epoch:156, loss:0.149735, acc:0.985873,  val_loss:7.779863, val_acc:0.324486,  val_acc-acc = -66.14%,  lr:0.000010  [31.14 sec]\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.36473\n",
            "epoch:157, loss:0.143430, acc:0.988014,  val_loss:7.829319, val_acc:0.324486,  val_acc-acc = -66.35%,  lr:0.000003  [31.14 sec]\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.36473\n",
            "epoch:158, loss:0.147010, acc:0.988014,  val_loss:7.755975, val_acc:0.323630,  val_acc-acc = -66.44%,  lr:0.000010  [31.15 sec]\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.36473\n",
            "epoch:159, loss:0.143020, acc:0.990154,  val_loss:7.848140, val_acc:0.327911,  val_acc-acc = -66.22%,  lr:0.000010  [31.12 sec]\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.36473\n",
            "epoch:160, loss:0.144459, acc:0.988014,  val_loss:7.819624, val_acc:0.322774,  val_acc-acc = -66.52%,  lr:0.000010  [31.11 sec]\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.36473\n",
            "epoch:161, loss:0.149273, acc:0.986943,  val_loss:7.815318, val_acc:0.323630,  val_acc-acc = -66.33%,  lr:0.000010  [31.16 sec]\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.36473\n",
            "epoch:162, loss:0.143342, acc:0.990368,  val_loss:7.819588, val_acc:0.323630,  val_acc-acc = -66.67%,  lr:0.000000  [31.14 sec]\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.36473\n",
            "epoch:163, loss:0.143675, acc:0.988014,  val_loss:7.824668, val_acc:0.324486,  val_acc-acc = -66.35%,  lr:0.000001  [31.17 sec]\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.36473\n",
            "epoch:164, loss:0.147282, acc:0.988228,  val_loss:7.841797, val_acc:0.323630,  val_acc-acc = -66.46%,  lr:0.000001  [31.11 sec]\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.36473\n",
            "epoch:165, loss:0.144281, acc:0.988442,  val_loss:7.820205, val_acc:0.324486,  val_acc-acc = -66.40%,  lr:0.000001  [31.05 sec]\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.36473\n",
            "epoch:166, loss:0.148772, acc:0.987372,  val_loss:7.811361, val_acc:0.323630,  val_acc-acc = -66.37%,  lr:0.000001  [31.02 sec]\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.36473\n",
            "epoch:167, loss:0.143674, acc:0.988656,  val_loss:7.826431, val_acc:0.324486,  val_acc-acc = -66.42%,  lr:0.000000  [31.03 sec]\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.36473\n",
            "epoch:168, loss:0.143957, acc:0.990368,  val_loss:7.815593, val_acc:0.324486,  val_acc-acc = -66.59%,  lr:0.000001  [31.07 sec]\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.36473\n",
            "epoch:169, loss:0.138998, acc:0.991438,  val_loss:7.810464, val_acc:0.324486,  val_acc-acc = -66.70%,  lr:0.000001  [31.07 sec]\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.36473\n",
            "epoch:170, loss:0.145079, acc:0.989084,  val_loss:7.823362, val_acc:0.325342,  val_acc-acc = -66.37%,  lr:0.000001  [31.15 sec]\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.36473\n",
            "epoch:171, loss:0.143950, acc:0.989726,  val_loss:7.824177, val_acc:0.324486,  val_acc-acc = -66.52%,  lr:0.000001  [31.02 sec]\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.36473\n",
            "epoch:172, loss:0.142884, acc:0.988870,  val_loss:7.820175, val_acc:0.324486,  val_acc-acc = -66.44%,  lr:0.000000  [31.21 sec]\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.36473\n",
            "epoch:173, loss:0.144896, acc:0.988442,  val_loss:7.825748, val_acc:0.324486,  val_acc-acc = -66.40%,  lr:0.000001  [31.15 sec]\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.36473\n",
            "epoch:174, loss:0.146359, acc:0.987372,  val_loss:7.829380, val_acc:0.325342,  val_acc-acc = -66.20%,  lr:0.000001  [31.23 sec]\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.36473\n",
            "epoch:175, loss:0.144370, acc:0.988870,  val_loss:7.839468, val_acc:0.326199,  val_acc-acc = -66.27%,  lr:0.000001  [31.06 sec]\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.36473\n",
            "epoch:176, loss:0.142852, acc:0.988442,  val_loss:7.844038, val_acc:0.325342,  val_acc-acc = -66.31%,  lr:0.000001  [31.03 sec]\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.36473\n",
            "epoch:177, loss:0.144506, acc:0.989512,  val_loss:7.836197, val_acc:0.326199,  val_acc-acc = -66.33%,  lr:0.000000  [31.00 sec]\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.36473\n",
            "epoch:178, loss:0.143448, acc:0.988014,  val_loss:7.837597, val_acc:0.326199,  val_acc-acc = -66.18%,  lr:0.000001  [31.03 sec]\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.36473\n",
            "epoch:179, loss:0.139857, acc:0.989940,  val_loss:7.839204, val_acc:0.325342,  val_acc-acc = -66.46%,  lr:0.000001  [31.06 sec]\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.36473\n",
            "epoch:180, loss:0.140512, acc:0.989512,  val_loss:7.840572, val_acc:0.326199,  val_acc-acc = -66.33%,  lr:0.000001  [31.08 sec]\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.36473\n",
            "epoch:181, loss:0.147710, acc:0.986301,  val_loss:7.838514, val_acc:0.326199,  val_acc-acc = -66.01%,  lr:0.000001  [31.14 sec]\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.36473\n",
            "epoch:182, loss:0.144832, acc:0.987372,  val_loss:7.840436, val_acc:0.325342,  val_acc-acc = -66.20%,  lr:0.000000  [31.00 sec]\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.36473\n",
            "epoch:183, loss:0.137618, acc:0.991438,  val_loss:7.846113, val_acc:0.325342,  val_acc-acc = -66.61%,  lr:0.000000  [31.05 sec]\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.36473\n",
            "epoch:184, loss:0.144529, acc:0.986943,  val_loss:7.836631, val_acc:0.326199,  val_acc-acc = -66.07%,  lr:0.000000  [31.25 sec]\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.36473\n",
            "epoch:185, loss:0.140153, acc:0.991866,  val_loss:7.850323, val_acc:0.326199,  val_acc-acc = -66.57%,  lr:0.000000  [31.13 sec]\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.36473\n",
            "epoch:186, loss:0.144712, acc:0.987586,  val_loss:7.834956, val_acc:0.326199,  val_acc-acc = -66.14%,  lr:0.000000  [31.25 sec]\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.36473\n",
            "epoch:187, loss:0.145859, acc:0.986943,  val_loss:7.838424, val_acc:0.326199,  val_acc-acc = -66.07%,  lr:0.000000  [31.06 sec]\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.36473\n",
            "epoch:188, loss:0.138947, acc:0.989940,  val_loss:7.850092, val_acc:0.325342,  val_acc-acc = -66.46%,  lr:0.000000  [31.10 sec]\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.36473\n",
            "epoch:189, loss:0.145198, acc:0.986729,  val_loss:7.828563, val_acc:0.326199,  val_acc-acc = -66.05%,  lr:0.000000  [31.10 sec]\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.36473\n",
            "epoch:190, loss:0.144417, acc:0.987800,  val_loss:7.842515, val_acc:0.326199,  val_acc-acc = -66.16%,  lr:0.000000  [31.17 sec]\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.36473\n",
            "epoch:191, loss:0.141737, acc:0.989298,  val_loss:7.841630, val_acc:0.326199,  val_acc-acc = -66.31%,  lr:0.000000  [31.22 sec]\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.36473\n",
            "epoch:192, loss:0.142456, acc:0.988870,  val_loss:7.849726, val_acc:0.326199,  val_acc-acc = -66.27%,  lr:0.000000  [31.13 sec]\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.36473\n",
            "epoch:193, loss:0.140669, acc:0.991438,  val_loss:7.840753, val_acc:0.326199,  val_acc-acc = -66.52%,  lr:0.000000  [31.21 sec]\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.36473\n",
            "epoch:194, loss:0.142249, acc:0.990368,  val_loss:7.828635, val_acc:0.326199,  val_acc-acc = -66.42%,  lr:0.000000  [31.24 sec]\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.36473\n",
            "epoch:195, loss:0.144169, acc:0.989726,  val_loss:7.843536, val_acc:0.325342,  val_acc-acc = -66.44%,  lr:0.000000  [31.16 sec]\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.36473\n",
            "epoch:196, loss:0.139969, acc:0.990368,  val_loss:7.847714, val_acc:0.325342,  val_acc-acc = -66.50%,  lr:0.000000  [31.27 sec]\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.36473\n",
            "epoch:197, loss:0.146798, acc:0.987586,  val_loss:7.864702, val_acc:0.326199,  val_acc-acc = -66.14%,  lr:0.000000  [31.13 sec]\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.36473\n",
            "epoch:198, loss:0.141066, acc:0.990796,  val_loss:7.859030, val_acc:0.326199,  val_acc-acc = -66.46%,  lr:0.000000  [31.25 sec]\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.36473\n",
            "epoch:199, loss:0.142831, acc:0.989084,  val_loss:7.853973, val_acc:0.325342,  val_acc-acc = -66.37%,  lr:0.000000  [31.19 sec]\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.36473\n",
            "epoch:200, loss:0.146161, acc:0.986729,  val_loss:7.848007, val_acc:0.326199,  val_acc-acc = -66.05%,  lr:0.000000  [31.21 sec]\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.36473\n",
            "37/37 [==============================] - 2s 58ms/step - loss: 7.8480 - acc: 0.3262\n",
            "Test loss: 7.8480072021484375\n",
            "Test accuracy: 0.32619863748550415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "koepeKnvQAQa",
        "outputId": "3046963e-e183-489f-c04a-d10c909f63b9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('%')\n",
        "plt.legend(('acc','val-acc'))\n",
        "plt.grid(b=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o88Re8HwQCGA",
        "outputId": "636e39f8-99e9-42d2-a250-3c1003dc9e2c"
      },
      "source": [
        "model.save('resnet20Diamant.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: resnet20Diamant.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV43us_SQI2-"
      },
      "source": [
        "model = tf.keras.models.load_model(\"resnet20Diamant.model\")\n",
        "prediction = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJr-lv8xQKX7",
        "outputId": "3a95f7b2-5cae-4b28-b4e5-b3e065923a68"
      },
      "source": [
        "with np.printoptions(threshold=np.inf):\n",
        "    print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.013 0.987]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.991 0.009]\n",
            " [0.    0.222 0.778]\n",
            " [0.001 0.821 0.177]\n",
            " [0.991 0.    0.009]\n",
            " [0.581 0.419 0.   ]\n",
            " [0.    0.002 0.998]\n",
            " [0.013 0.122 0.865]\n",
            " [0.028 0.001 0.972]\n",
            " [0.003 0.002 0.995]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.037 0.002 0.961]\n",
            " [0.001 0.969 0.03 ]\n",
            " [0.    0.09  0.91 ]\n",
            " [0.    0.485 0.515]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.019 0.981]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.779 0.221]\n",
            " [0.104 0.    0.896]\n",
            " [0.833 0.164 0.003]\n",
            " [0.    0.97  0.03 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.061 0.939]\n",
            " [0.    0.001 0.999]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.007 0.993]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.967 0.033]\n",
            " [0.    0.984 0.016]\n",
            " [0.    0.011 0.989]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.016 0.984]\n",
            " [0.    0.001 0.999]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.434 0.566]\n",
            " [0.    0.988 0.012]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.864 0.136]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.05  0.95 ]\n",
            " [0.    0.04  0.96 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.027 0.973 0.   ]\n",
            " [0.    0.176 0.824]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.88  0.001 0.119]\n",
            " [0.    0.001 0.999]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.754 0.246]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.02  0.979]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    0.999]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.789 0.211]\n",
            " [0.    0.906 0.094]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.085 0.915]\n",
            " [0.    0.043 0.957]\n",
            " [0.    0.944 0.055]\n",
            " [0.    0.983 0.017]\n",
            " [0.    0.975 0.025]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.971 0.029]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.985 0.015]\n",
            " [0.    0.001 0.999]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.001 0.999]\n",
            " [0.997 0.003 0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.996 0.004]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.996 0.004]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.912 0.088]\n",
            " [0.042 0.001 0.956]\n",
            " [0.    0.891 0.109]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.318 0.682]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.015 0.985]\n",
            " [0.    0.999 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.021 0.979]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.993 0.007]\n",
            " [0.    0.969 0.031]\n",
            " [0.    0.396 0.604]\n",
            " [0.    0.018 0.982]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.179 0.821]\n",
            " [0.    0.611 0.389]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.997 0.003]\n",
            " [0.    1.    0.   ]\n",
            " [0.087 0.002 0.912]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.719 0.281]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.002 0.998]\n",
            " [0.    0.234 0.766]\n",
            " [0.001 0.959 0.04 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.001 0.999]\n",
            " [0.998 0.    0.002]\n",
            " [0.    0.99  0.01 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.948 0.052]\n",
            " [0.    0.526 0.474]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.439 0.561]\n",
            " [0.    1.    0.   ]\n",
            " [0.017 0.162 0.821]\n",
            " [1.    0.    0.   ]\n",
            " [0.21  0.072 0.718]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.112 0.865 0.023]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.116 0.883 0.001]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.998 0.002]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.904 0.096]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.718 0.282]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.649 0.351]\n",
            " [0.002 0.898 0.1  ]\n",
            " [0.    0.55  0.45 ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.043 0.957]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.002 0.314 0.684]\n",
            " [0.    0.993 0.007]\n",
            " [0.    0.974 0.026]\n",
            " [0.    1.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.998 0.002]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.797 0.202 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.081 0.012 0.907]\n",
            " [0.    0.323 0.677]\n",
            " [0.    0.997 0.003]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.886 0.114]\n",
            " [0.    0.91  0.09 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.954 0.045]\n",
            " [0.    0.986 0.014]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.002 0.97  0.028]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.671 0.328]\n",
            " [0.    0.919 0.081]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.564 0.435]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.975 0.025]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.836 0.164]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.992 0.008]\n",
            " [0.002 0.034 0.964]\n",
            " [0.    0.932 0.068]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.992 0.008]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.68  0.32 ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.938 0.    0.062]\n",
            " [0.001 0.    0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.01  0.83  0.159]\n",
            " [0.    0.265 0.735]\n",
            " [0.    0.018 0.982]\n",
            " [0.    0.132 0.868]\n",
            " [0.002 0.    0.998]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.04  0.96 ]\n",
            " [0.    0.005 0.995]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.991 0.009]\n",
            " [0.    0.866 0.134]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.564 0.436]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.861 0.139]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.975 0.024]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.011 0.989]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.068 0.059 0.873]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.908 0.092]\n",
            " [0.    0.021 0.979]\n",
            " [0.742 0.241 0.017]\n",
            " [0.    0.002 0.998]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.509 0.491]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.988 0.012]\n",
            " [0.008 0.143 0.849]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.001 0.112 0.887]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.982 0.017]\n",
            " [0.    0.002 0.998]\n",
            " [0.    0.327 0.673]\n",
            " [0.458 0.525 0.017]\n",
            " [0.    0.106 0.894]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.075 0.925]\n",
            " [0.    0.925 0.075]\n",
            " [0.997 0.    0.003]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.51  0.007 0.483]\n",
            " [0.    0.948 0.052]\n",
            " [0.    0.483 0.517]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.22  0.78 ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.115 0.885]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.053 0.947]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.265 0.735]\n",
            " [0.    0.    1.   ]\n",
            " [0.359 0.003 0.639]\n",
            " [0.767 0.233 0.001]\n",
            " [0.    0.997 0.003]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.153 0.4   0.447]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.011 0.989]\n",
            " [0.077 0.042 0.881]\n",
            " [0.    0.763 0.237]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.001 0.998]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    0.999]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.836 0.164]\n",
            " [0.    0.908 0.092]\n",
            " [0.    0.959 0.041]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.492 0.508]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.174 0.826]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.013 0.987]\n",
            " [0.    0.004 0.996]\n",
            " [0.    0.952 0.048]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.993 0.007]\n",
            " [0.    0.999 0.001]\n",
            " [0.812 0.098 0.09 ]\n",
            " [0.001 0.697 0.302]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.3   0.7  ]\n",
            " [0.    0.78  0.22 ]\n",
            " [0.    0.999 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.538 0.462]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.954 0.046]\n",
            " [0.    0.993 0.007]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.993 0.007]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.061 0.208 0.731]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.985 0.015]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.994 0.006]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.437 0.563]\n",
            " [0.938 0.062 0.   ]\n",
            " [0.    0.723 0.277]\n",
            " [0.    0.002 0.998]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.99  0.01 ]\n",
            " [0.    0.994 0.006]\n",
            " [0.997 0.001 0.002]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.994 0.006]\n",
            " [0.    0.982 0.018]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.989 0.011]\n",
            " [0.002 0.551 0.448]\n",
            " [0.    0.055 0.945]\n",
            " [0.    0.963 0.037]\n",
            " [0.    0.885 0.115]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.005 0.995]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.989 0.011]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.001 0.869 0.13 ]\n",
            " [0.    0.998 0.002]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.418 0.582]\n",
            " [0.    0.007 0.993]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.639 0.361]\n",
            " [0.    0.995 0.005]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [1.    0.    0.   ]\n",
            " [0.003 0.001 0.996]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.978 0.022]\n",
            " [0.999 0.    0.001]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.006 0.994]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.577 0.423]\n",
            " [0.    0.57  0.43 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.005 0.253 0.742]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.005 0.132 0.864]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.994 0.006]\n",
            " [0.32  0.646 0.034]\n",
            " [0.    0.005 0.995]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.95  0.05 ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.006 0.994]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.33  0.67 ]\n",
            " [0.    0.044 0.956]\n",
            " [0.859 0.019 0.122]\n",
            " [1.    0.    0.   ]\n",
            " [0.927 0.016 0.056]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.065 0.935]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.983 0.017]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.003 0.996]\n",
            " [0.001 0.004 0.995]\n",
            " [0.    0.476 0.524]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.242 0.756]\n",
            " [0.    0.001 0.999]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.972 0.001 0.027]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.022 0.978]\n",
            " [0.001 0.722 0.278]\n",
            " [0.73  0.27  0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.903 0.    0.097]\n",
            " [0.165 0.277 0.557]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.939 0.061]\n",
            " [0.    0.311 0.689]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.018 0.982 0.   ]\n",
            " [0.    0.913 0.087]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.003 0.997]\n",
            " [0.    0.8   0.2  ]\n",
            " [0.    0.046 0.954]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.69  0.31 ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.998 0.002]\n",
            " [0.492 0.    0.507]\n",
            " [0.    0.949 0.051]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.006 0.994]\n",
            " [0.669 0.005 0.326]\n",
            " [0.004 0.    0.996]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.993 0.007]\n",
            " [0.08  0.323 0.596]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.017 0.983]\n",
            " [0.    0.998 0.002]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.992 0.008]\n",
            " [0.    0.002 0.998]\n",
            " [0.005 0.01  0.985]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.276 0.724]\n",
            " [0.    0.991 0.009]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.373 0.627]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.264 0.736]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.875 0.125]\n",
            " [0.002 0.43  0.568]\n",
            " [0.    0.996 0.004]\n",
            " [0.009 0.493 0.498]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.164 0.836]\n",
            " [0.    0.998 0.002]\n",
            " [0.056 0.16  0.785]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.013 0.987]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.018 0.982]\n",
            " [0.    0.995 0.005]\n",
            " [0.    0.944 0.056]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.546 0.454]\n",
            " [0.    0.003 0.997]\n",
            " [0.972 0.019 0.009]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.546 0.454]\n",
            " [0.    0.04  0.96 ]\n",
            " [0.    0.995 0.005]\n",
            " [0.    0.979 0.021]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.724 0.276]\n",
            " [0.    0.999 0.001]\n",
            " [0.999 0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.946 0.054]\n",
            " [0.    0.994 0.005]\n",
            " [0.    0.982 0.018]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.967 0.033]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.203 0.797]\n",
            " [0.    0.992 0.008]\n",
            " [0.    0.315 0.684]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.606 0.394]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.776 0.224]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.994 0.006]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.017 0.983]\n",
            " [0.    0.002 0.998]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.987 0.013]\n",
            " [0.    0.993 0.007]\n",
            " [0.    0.08  0.92 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.199 0.801]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.69  0.31 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.578 0.002 0.42 ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.964 0.036]\n",
            " [0.    0.913 0.087]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.001 0.223 0.776]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.015 0.985]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.045 0.955]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.002 0.978 0.02 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.009 0.991]\n",
            " [1.    0.    0.   ]\n",
            " [0.846 0.    0.154]\n",
            " [0.    0.963 0.037]\n",
            " [0.017 0.983 0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.971 0.029]\n",
            " [0.    0.811 0.189]\n",
            " [0.    0.024 0.976]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.911 0.089]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.98  0.02 ]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.531 0.469]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.986 0.014]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.002 0.998]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.175 0.697 0.128]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.001 0.999]\n",
            " [0.003 0.427 0.57 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.998 0.002 0.   ]\n",
            " [0.    0.555 0.445]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.992 0.    0.008]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.003 0.991 0.006]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.023 0.977]\n",
            " [0.003 0.012 0.984]\n",
            " [0.    0.996 0.004]\n",
            " [0.    0.807 0.193]\n",
            " [0.003 0.127 0.87 ]\n",
            " [1.    0.    0.   ]\n",
            " [0.531 0.032 0.437]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.874 0.106 0.02 ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.002 0.997 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.992 0.008]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.998 0.002 0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.755 0.245 0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.188 0.    0.812]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.882 0.118]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.995 0.005]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.94  0.06 ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.326 0.    0.674]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.56  0.437 0.003]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.972 0.028]\n",
            " [0.667 0.006 0.327]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.056 0.349 0.595]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.97  0.03 ]\n",
            " [0.121 0.012 0.868]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.094 0.906 0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.949 0.051]\n",
            " [0.    0.937 0.063]\n",
            " [0.09  0.039 0.87 ]\n",
            " [0.023 0.001 0.976]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.002 0.998 0.   ]\n",
            " [0.007 0.001 0.992]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.001 0.999]\n",
            " [0.212 0.095 0.693]\n",
            " [0.    0.05  0.95 ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [1.    0.    0.   ]\n",
            " [0.923 0.04  0.037]\n",
            " [0.    0.798 0.202]\n",
            " [0.062 0.108 0.83 ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.031 0.969 0.001]\n",
            " [0.985 0.    0.015]\n",
            " [0.    0.965 0.035]\n",
            " [0.98  0.009 0.011]\n",
            " [0.995 0.    0.005]\n",
            " [0.    0.004 0.996]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.002 0.998]\n",
            " [0.193 0.026 0.78 ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.828 0.172]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.159 0.841]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.988 0.012]\n",
            " [0.342 0.531 0.127]\n",
            " [0.682 0.    0.318]\n",
            " [0.988 0.    0.012]\n",
            " [0.    1.    0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.073 0.927]\n",
            " [0.994 0.    0.006]\n",
            " [0.    0.006 0.994]\n",
            " [1.    0.    0.   ]\n",
            " [0.095 0.005 0.9  ]\n",
            " [0.    0.    1.   ]\n",
            " [0.228 0.181 0.59 ]\n",
            " [0.007 0.019 0.974]\n",
            " [0.646 0.161 0.193]\n",
            " [0.    1.    0.   ]\n",
            " [0.505 0.399 0.096]\n",
            " [0.    0.043 0.957]\n",
            " [0.001 0.999 0.   ]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.    1.   ]\n",
            " [0.173 0.827 0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.99  0.01 ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.994 0.006]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.097 0.903]\n",
            " [0.    0.989 0.011]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.999 0.   ]\n",
            " [0.    0.993 0.007]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.006 0.005 0.99 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.058 0.942]\n",
            " [0.    0.785 0.215]\n",
            " [0.001 0.245 0.754]\n",
            " [0.    0.942 0.058]\n",
            " [0.    0.841 0.159]\n",
            " [0.    0.17  0.83 ]\n",
            " [0.001 0.999 0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.885 0.115]\n",
            " [0.    0.981 0.019]\n",
            " [0.    0.119 0.881]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.825 0.175]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.994 0.006]\n",
            " [0.001 0.009 0.99 ]\n",
            " [0.    0.123 0.877]\n",
            " [0.    0.996 0.004]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.002 0.019 0.98 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.794 0.206]\n",
            " [0.241 0.048 0.711]\n",
            " [0.    0.978 0.022]\n",
            " [0.    0.999 0.001]\n",
            " [0.249 0.012 0.739]\n",
            " [0.081 0.917 0.002]\n",
            " [0.979 0.    0.021]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.055 0.945]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.886 0.114]\n",
            " [0.    1.    0.   ]\n",
            " [0.005 0.    0.995]\n",
            " [0.    0.068 0.932]\n",
            " [0.    0.495 0.505]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.008 0.992]\n",
            " [0.    0.134 0.866]\n",
            " [0.096 0.043 0.862]\n",
            " [0.048 0.422 0.53 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.001 0.999 0.   ]\n",
            " [0.001 0.791 0.208]\n",
            " [0.992 0.004 0.003]\n",
            " [0.    1.    0.   ]\n",
            " [0.059 0.053 0.888]\n",
            " [0.    0.045 0.955]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.999 0.001]\n",
            " [0.853 0.105 0.042]\n",
            " [0.001 0.018 0.981]\n",
            " [0.013 0.003 0.983]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.05  0.779 0.171]\n",
            " [0.014 0.945 0.041]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.12  0.88 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.009 0.741 0.25 ]\n",
            " [0.    0.995 0.005]\n",
            " [0.    0.003 0.997]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.001 0.043 0.956]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.031 0.969]\n",
            " [0.    0.005 0.995]\n",
            " [0.    0.002 0.998]\n",
            " [0.    0.035 0.965]\n",
            " [0.002 0.909 0.089]\n",
            " [0.    0.001 0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.741 0.259]\n",
            " [0.006 0.    0.994]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.996 0.004]\n",
            " [0.001 0.778 0.221]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.283 0.716]\n",
            " [0.    0.998 0.002]\n",
            " [0.991 0.    0.009]\n",
            " [0.003 0.899 0.098]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.224 0.776]\n",
            " [0.    0.963 0.037]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.719 0.281]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.995 0.005]\n",
            " [0.    0.99  0.01 ]\n",
            " [0.    0.925 0.075]\n",
            " [0.001 0.324 0.676]\n",
            " [0.    0.998 0.002]\n",
            " [0.    0.948 0.052]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.2   0.8  ]\n",
            " [0.    0.988 0.012]\n",
            " [0.004 0.918 0.078]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.913 0.087]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.116 0.52  0.364]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.006 0.993]\n",
            " [0.002 0.002 0.996]\n",
            " [0.    0.995 0.005]\n",
            " [0.852 0.146 0.002]\n",
            " [0.    0.205 0.795]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.308 0.692]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.043 0.957]\n",
            " [0.157 0.821 0.022]\n",
            " [0.    0.025 0.975]\n",
            " [0.    0.994 0.006]\n",
            " [0.386 0.37  0.244]\n",
            " [0.    0.072 0.928]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.027 0.973]\n",
            " [0.    0.022 0.978]\n",
            " [0.    0.068 0.932]\n",
            " [0.965 0.034 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.975 0.025]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.022 0.978]\n",
            " [0.    0.98  0.02 ]\n",
            " [0.    0.982 0.018]\n",
            " [0.    0.093 0.907]\n",
            " [0.098 0.778 0.124]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.984 0.016]\n",
            " [0.    0.995 0.005]\n",
            " [0.    0.997 0.003]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.997 0.003]\n",
            " [0.005 0.995 0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.982 0.018]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.984 0.016]\n",
            " [0.    0.075 0.925]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.144 0.856]\n",
            " [0.274 0.724 0.003]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.353 0.647]\n",
            " [0.    0.008 0.992]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.985 0.015]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.819 0.128 0.053]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.98  0.02 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.987 0.013]\n",
            " [0.    0.999 0.001]\n",
            " [0.038 0.799 0.163]\n",
            " [0.906 0.    0.094]\n",
            " [0.    0.002 0.998]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.94  0.06 ]\n",
            " [0.    0.935 0.065]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.942 0.058]\n",
            " [0.    0.95  0.05 ]\n",
            " [0.    0.999 0.001]\n",
            " [0.    0.843 0.157]\n",
            " [0.    0.151 0.849]\n",
            " [0.    0.916 0.084]\n",
            " [0.    0.404 0.596]\n",
            " [0.    0.002 0.998]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.986 0.013]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.974 0.026]\n",
            " [0.904 0.    0.095]\n",
            " [0.    0.017 0.983]\n",
            " [0.    0.96  0.04 ]\n",
            " [0.    0.031 0.969]\n",
            " [0.    0.117 0.883]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.851 0.    0.149]\n",
            " [0.268 0.716 0.016]\n",
            " [0.    0.453 0.547]\n",
            " [0.066 0.69  0.243]\n",
            " [0.    0.637 0.362]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.972 0.028]\n",
            " [0.    0.949 0.051]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.029 0.971]\n",
            " [0.    0.952 0.047]\n",
            " [0.765 0.172 0.064]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.999 0.001]\n",
            " [0.096 0.903 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.991 0.009]\n",
            " [0.    0.006 0.994]\n",
            " [0.    0.42  0.58 ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.217 0.783]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.01  0.99 ]\n",
            " [0.    0.997 0.003]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.995 0.005]\n",
            " [0.    0.649 0.351]\n",
            " [0.    0.988 0.012]\n",
            " [0.    0.991 0.008]\n",
            " [0.    0.581 0.419]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.008 0.992]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.146 0.853]\n",
            " [0.    0.954 0.046]\n",
            " [0.    0.927 0.073]\n",
            " [0.    1.    0.   ]\n",
            " [0.577 0.421 0.002]\n",
            " [0.    0.391 0.609]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.998 0.002]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.018 0.982]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.877 0.123]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.996 0.004]\n",
            " [0.002 0.097 0.901]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.041 0.959]\n",
            " [0.001 0.998 0.001]\n",
            " [0.    0.064 0.936]\n",
            " [0.997 0.003 0.   ]\n",
            " [0.    0.978 0.022]\n",
            " [0.    0.001 0.999]\n",
            " [0.    0.021 0.979]\n",
            " [0.022 0.975 0.003]\n",
            " [0.    0.613 0.387]\n",
            " [0.    0.999 0.001]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.001 0.999]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.914 0.086]\n",
            " [0.    0.985 0.015]\n",
            " [0.    0.973 0.027]\n",
            " [0.    0.985 0.015]\n",
            " [0.008 0.971 0.022]\n",
            " [0.    0.987 0.013]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.893 0.107]\n",
            " [0.019 0.881 0.1  ]\n",
            " [0.    0.731 0.269]\n",
            " [0.    1.    0.   ]\n",
            " [0.011 0.001 0.988]\n",
            " [0.04  0.501 0.459]\n",
            " [0.    0.961 0.039]\n",
            " [0.    0.005 0.995]\n",
            " [0.    0.051 0.949]\n",
            " [0.    0.96  0.04 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJcCGNOYQMiK"
      },
      "source": [
        "label_pred = np.array([np.argmax(prediction, axis=1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26PmIdRtQM3g",
        "outputId": "6c30919b-2214-45ee-f4b4-4cc56de3b841"
      },
      "source": [
        "print(label_pred.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [1]\n",
            " ...\n",
            " [2]\n",
            " [2]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szdedX6rQN_V",
        "outputId": "0e38b088-62ab-456c-a1ac-13626d548f60"
      },
      "source": [
        "predict_labels = np.array(test_labels.drop(['class_id'],axis=1))\n",
        "predict_labels = np.append(predict_labels,label_pred.T,axis=1)\n",
        "with np.printoptions(threshold=np.inf):\n",
        "    print(predict_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['img_6309102362127931879.jpg' 0]\n",
            " ['img_2031896927656989520.jpg' 0]\n",
            " ['img_4693592482016108254.jpg' 1]\n",
            " ['img_1731353163814999872.jpg' 2]\n",
            " ['img_4270405616056570211.jpg' 2]\n",
            " ['img_5592512817605259347.jpg' 2]\n",
            " ['img_7270920511344208641.jpg' 1]\n",
            " ['img_8750976362013359084.jpg' 2]\n",
            " ['img_3099813306519204140.jpg' 1]\n",
            " ['img_6152245361589836720.jpg' 0]\n",
            " ['img_5133964404089301517.jpg' 0]\n",
            " ['img_6094498399694976619.jpg' 2]\n",
            " ['img_5009290568007555183.jpg' 2]\n",
            " ['img_91583952582106774.jpg' 2]\n",
            " ['img_6172231491103496150.jpg' 2]\n",
            " ['img_7279243678066448832.jpg' 0]\n",
            " ['img_1508041442905435888.jpg' 0]\n",
            " ['img_5834118063979502391.jpg' 2]\n",
            " ['img_6587768937848096651.jpg' 1]\n",
            " ['img_3077954441619156589.jpg' 2]\n",
            " ['img_3655945510172717944.jpg' 2]\n",
            " ['img_3153198158239991036.jpg' 0]\n",
            " ['img_8068040535899796305.jpg' 1]\n",
            " ['img_785206936656049715.jpg' 0]\n",
            " ['img_4635476933370359163.jpg' 1]\n",
            " ['img_7081409369711501166.jpg' 1]\n",
            " ['img_8166760919851749947.jpg' 0]\n",
            " ['img_8669652425730035268.jpg' 0]\n",
            " ['img_7169925662333297601.jpg' 1]\n",
            " ['img_3646563474908226387.jpg' 0]\n",
            " ['img_8792668570660383954.jpg' 2]\n",
            " ['img_3327303078605799907.jpg' 0]\n",
            " ['img_4617561666437688566.jpg' 0]\n",
            " ['img_4007021455477149376.jpg' 0]\n",
            " ['img_7814062774888432606.jpg' 1]\n",
            " ['img_2253257452262343698.jpg' 0]\n",
            " ['img_964871010548180978.jpg' 1]\n",
            " ['img_464679800778781795.jpg' 2]\n",
            " ['img_7015453414791838167.jpg' 0]\n",
            " ['img_3176758972793577728.jpg' 1]\n",
            " ['img_4631761529288557328.jpg' 0]\n",
            " ['img_5199740163580192436.jpg' 2]\n",
            " ['img_978609420867177867.jpg' 2]\n",
            " ['img_5217425641583516650.jpg' 0]\n",
            " ['img_620989576219938004.jpg' 0]\n",
            " ['img_8410835316270795839.jpg' 2]\n",
            " ['img_5446487315543420953.jpg' 0]\n",
            " ['img_4150237230948361912.jpg' 1]\n",
            " ['img_7890692936017505787.jpg' 1]\n",
            " ['img_3746457407515000835.jpg' 2]\n",
            " ['img_2194948826011416115.jpg' 1]\n",
            " ['img_4176566142282456918.jpg' 0]\n",
            " ['img_943999834212424978.jpg' 0]\n",
            " ['img_1552046074896059811.jpg' 0]\n",
            " ['img_8698713679468389782.jpg' 2]\n",
            " ['img_7080266259457443026.jpg' 2]\n",
            " ['img_8986791111430816779.jpg' 0]\n",
            " ['img_940795375577965597.jpg' 2]\n",
            " ['img_6246748883754323497.jpg' 1]\n",
            " ['img_6699120282244151366.jpg' 0]\n",
            " ['img_4837554644720882146.jpg' 1]\n",
            " ['img_81746619137058812.jpg' 0]\n",
            " ['img_231229768526514457.jpg' 0]\n",
            " ['img_5163714155267413382.jpg' 2]\n",
            " ['img_8430996124069986226.jpg' 2]\n",
            " ['img_935944140711976007.jpg' 0]\n",
            " ['img_6170651461352000542.jpg' 1]\n",
            " ['img_5027803105548136850.jpg' 2]\n",
            " ['img_8225408931242425134.jpg' 1]\n",
            " ['img_4662945103395400145.jpg' 0]\n",
            " ['img_5819126029704876911.jpg' 0]\n",
            " ['img_5938425601053486100.jpg' 0]\n",
            " ['img_464133314152277619.jpg' 2]\n",
            " ['img_4951089576775246707.jpg' 0]\n",
            " ['img_4860253779451897720.jpg' 2]\n",
            " ['img_626205162271840095.jpg' 1]\n",
            " ['img_2574635824564989675.jpg' 0]\n",
            " ['img_3933361025036022314.jpg' 1]\n",
            " ['img_8737107079041398394.jpg' 1]\n",
            " ['img_113945781825697157.jpg' 0]\n",
            " ['img_4751082233760448470.jpg' 1]\n",
            " ['img_7227354360494212144.jpg' 2]\n",
            " ['img_5897303873170558773.jpg' 1]\n",
            " ['img_452247036849068915.jpg' 2]\n",
            " ['img_6060234204831949153.jpg' 0]\n",
            " ['img_4361352157855573458.jpg' 0]\n",
            " ['img_1125305094391727652.jpg' 1]\n",
            " ['img_8992086446333146158.jpg' 1]\n",
            " ['img_4509931794702793182.jpg' 2]\n",
            " ['img_7637427230703012538.jpg' 2]\n",
            " ['img_940547819247382350.jpg' 2]\n",
            " ['img_9014653839142902124.jpg' 1]\n",
            " ['img_3267847216652763662.jpg' 1]\n",
            " ['img_6153208486815378200.jpg' 1]\n",
            " ['img_7927630130057387492.jpg' 0]\n",
            " ['img_8405810591210253673.jpg' 1]\n",
            " ['img_4594211373927948427.jpg' 1]\n",
            " ['img_8652461128739025659.jpg' 1]\n",
            " ['img_521059838039138323.jpg' 2]\n",
            " ['img_1037910048520457739.jpg' 1]\n",
            " ['img_5753655085907846586.jpg' 0]\n",
            " ['img_2294160886556350704.jpg' 1]\n",
            " ['img_6107523458443060070.jpg' 2]\n",
            " ['img_8376321365172036610.jpg' 0]\n",
            " ['img_3502429438286901288.jpg' 1]\n",
            " ['img_3497781612282889737.jpg' 1]\n",
            " ['img_7739679301403646757.jpg' 1]\n",
            " ['img_1918697283940589822.jpg' 1]\n",
            " ['img_4012594844139140403.jpg' 0]\n",
            " ['img_1937324420677230021.jpg' 0]\n",
            " ['img_7836394463489798514.jpg' 0]\n",
            " ['img_6803968268831810646.jpg' 0]\n",
            " ['img_715191042984464273.jpg' 1]\n",
            " ['img_7410146721513973755.jpg' 2]\n",
            " ['img_7392973100552976377.jpg' 1]\n",
            " ['img_1936537180421269556.jpg' 0]\n",
            " ['img_1136104169519514555.jpg' 1]\n",
            " ['img_8942459916608348827.jpg' 1]\n",
            " ['img_3600273992645587466.jpg' 2]\n",
            " ['img_1548475923574347498.jpg' 0]\n",
            " ['img_4610568925036507349.jpg' 2]\n",
            " ['img_7112749593525116141.jpg' 1]\n",
            " ['img_1624000297803319439.jpg' 0]\n",
            " ['img_5766855487820295664.jpg' 2]\n",
            " ['img_5311403885450605494.jpg' 0]\n",
            " ['img_1344066489518845796.jpg' 1]\n",
            " ['img_3412469675441814585.jpg' 1]\n",
            " ['img_8300463119490659390.jpg' 2]\n",
            " ['img_7860918354545811144.jpg' 2]\n",
            " ['img_3990715117429954568.jpg' 0]\n",
            " ['img_8364952418880606790.jpg' 2]\n",
            " ['img_5382799512927463067.jpg' 2]\n",
            " ['img_5510708783964509110.jpg' 1]\n",
            " ['img_3749195325059456679.jpg' 0]\n",
            " ['img_3046743433416058694.jpg' 1]\n",
            " ['img_5663015279939449352.jpg' 1]\n",
            " ['img_7579191960631562497.jpg' 1]\n",
            " ['img_6449886987310420287.jpg' 1]\n",
            " ['img_4685024526119252968.jpg' 2]\n",
            " ['img_8891051949666518222.jpg' 1]\n",
            " ['img_819878597134835112.jpg' 1]\n",
            " ['img_6298968408181684121.jpg' 2]\n",
            " ['img_1951693331103726491.jpg' 2]\n",
            " ['img_4910389977179238344.jpg' 2]\n",
            " ['img_220493306489352574.jpg' 1]\n",
            " ['img_5971100287742361218.jpg' 1]\n",
            " ['img_979768917951898241.jpg' 2]\n",
            " ['img_5076598007460396740.jpg' 0]\n",
            " ['img_5435456626801938341.jpg' 1]\n",
            " ['img_1420981714339712135.jpg' 0]\n",
            " ['img_3348846524335426749.jpg' 1]\n",
            " ['img_9111559882594884562.jpg' 1]\n",
            " ['img_7028222205567846200.jpg' 0]\n",
            " ['img_7089721220396806395.jpg' 2]\n",
            " ['img_5027358735626498231.jpg' 1]\n",
            " ['img_8562499387602960952.jpg' 2]\n",
            " ['img_3525918393340362313.jpg' 0]\n",
            " ['img_6892962492257073583.jpg' 2]\n",
            " ['img_5517510075729765528.jpg' 1]\n",
            " ['img_4246305079634655131.jpg' 0]\n",
            " ['img_4298385755409377646.jpg' 0]\n",
            " ['img_6565983379439628777.jpg' 1]\n",
            " ['img_3257469534634628222.jpg' 2]\n",
            " ['img_2746550248738272737.jpg' 1]\n",
            " ['img_6192831756087060662.jpg' 1]\n",
            " ['img_2596015915447378696.jpg' 0]\n",
            " ['img_7982328926394609711.jpg' 2]\n",
            " ['img_5827501590715401057.jpg' 1]\n",
            " ['img_4220022589157059944.jpg' 0]\n",
            " ['img_3462556728691272790.jpg' 1]\n",
            " ['img_314038186807071902.jpg' 0]\n",
            " ['img_4766808303601779343.jpg' 0]\n",
            " ['img_1085919836874816265.jpg' 0]\n",
            " ['img_2626209614289632180.jpg' 0]\n",
            " ['img_8241657572112639516.jpg' 1]\n",
            " ['img_4452166620436873003.jpg' 2]\n",
            " ['img_5664132683964640077.jpg' 1]\n",
            " ['img_5610328875930344875.jpg' 0]\n",
            " ['img_4831054692309035671.jpg' 1]\n",
            " ['img_8038162911143340318.jpg' 0]\n",
            " ['img_8986265928968147485.jpg' 1]\n",
            " ['img_5672384118490209416.jpg' 0]\n",
            " ['img_2573186073877494994.jpg' 1]\n",
            " ['img_2257305286976174058.jpg' 1]\n",
            " ['img_384481436704990912.jpg' 1]\n",
            " ['img_2828931721287902159.jpg' 1]\n",
            " ['img_4330255769055414843.jpg' 0]\n",
            " ['img_3596226496661224082.jpg' 1]\n",
            " ['img_3198500126657487833.jpg' 1]\n",
            " ['img_990164178298384626.jpg' 2]\n",
            " ['img_2071111415136020240.jpg' 0]\n",
            " ['img_5499648232019004792.jpg' 1]\n",
            " ['img_6630169353874321881.jpg' 2]\n",
            " ['img_8254169436462973428.jpg' 1]\n",
            " ['img_2692551116820088059.jpg' 1]\n",
            " ['img_8045181659937663639.jpg' 1]\n",
            " ['img_2846284418015886176.jpg' 0]\n",
            " ['img_8097175539930500600.jpg' 1]\n",
            " ['img_5493616577320392328.jpg' 0]\n",
            " ['img_1642158356079022817.jpg' 0]\n",
            " ['img_7280376904893749428.jpg' 0]\n",
            " ['img_3058865476659937668.jpg' 1]\n",
            " ['img_934716473613546643.jpg' 2]\n",
            " ['img_7598272795322321017.jpg' 2]\n",
            " ['img_7891725722636836114.jpg' 1]\n",
            " ['img_391143136263482229.jpg' 1]\n",
            " ['img_5432562393131859665.jpg' 1]\n",
            " ['img_6624163470102737010.jpg' 1]\n",
            " ['img_5762312520682583265.jpg' 1]\n",
            " ['img_5476174903474698915.jpg' 1]\n",
            " ['img_4098086470608758423.jpg' 1]\n",
            " ['img_337181207951221940.jpg' 1]\n",
            " ['img_7694044688344434449.jpg' 1]\n",
            " ['img_3032664405909749325.jpg' 0]\n",
            " ['img_25068669476279765.jpg' 1]\n",
            " ['img_4226502573786592836.jpg' 0]\n",
            " ['img_6846983012998718240.jpg' 1]\n",
            " ['img_4019671766211340579.jpg' 0]\n",
            " ['img_5568919095695087822.jpg' 1]\n",
            " ['img_8900575666276350946.jpg' 1]\n",
            " ['img_840591881850973830.jpg' 1]\n",
            " ['img_6207768701565255740.jpg' 1]\n",
            " ['img_832583364100642167.jpg' 1]\n",
            " ['img_3440384973840643163.jpg' 1]\n",
            " ['img_8780545602578352771.jpg' 1]\n",
            " ['img_3368800998434121772.jpg' 0]\n",
            " ['img_7836630437651245731.jpg' 1]\n",
            " ['img_6437516596914537837.jpg' 0]\n",
            " ['img_7928806584815069540.jpg' 0]\n",
            " ['img_8736753162524330453.jpg' 1]\n",
            " ['img_7907301101751386514.jpg' 2]\n",
            " ['img_412737088629680987.jpg' 1]\n",
            " ['img_5301134503874260005.jpg' 0]\n",
            " ['img_7771075636589100959.jpg' 1]\n",
            " ['img_580980425376673762.jpg' 0]\n",
            " ['img_3129009562842236950.jpg' 1]\n",
            " ['img_993462071340140345.jpg' 0]\n",
            " ['img_6700016691784522029.jpg' 0]\n",
            " ['img_65431734813201303.jpg' 1]\n",
            " ['img_7072640692262914971.jpg' 0]\n",
            " ['img_6645687562288080204.jpg' 0]\n",
            " ['img_324197050407511663.jpg' 0]\n",
            " ['img_9001771978496515703.jpg' 2]\n",
            " ['img_3260059253178519612.jpg' 1]\n",
            " ['img_1502041667346724629.jpg' 1]\n",
            " ['img_7856678103585209500.jpg' 2]\n",
            " ['img_4887956437672263297.jpg' 2]\n",
            " ['img_8375661817661871014.jpg' 2]\n",
            " ['img_7476156299500994346.jpg' 2]\n",
            " ['img_8808282074404242637.jpg' 0]\n",
            " ['img_9177349114457614703.jpg' 0]\n",
            " ['img_4485073411067302517.jpg' 2]\n",
            " ['img_5096749692313347903.jpg' 2]\n",
            " ['img_8951895804680307923.jpg' 2]\n",
            " ['img_3014783467533453743.jpg' 1]\n",
            " ['img_4458925221687666812.jpg' 1]\n",
            " ['img_1540036830610905138.jpg' 0]\n",
            " ['img_7489430486287707662.jpg' 1]\n",
            " ['img_6844703638774016173.jpg' 0]\n",
            " ['img_7673098695107679754.jpg' 1]\n",
            " ['img_7562702319810113053.jpg' 2]\n",
            " ['img_1294542456946970879.jpg' 1]\n",
            " ['img_3423351138749347942.jpg' 1]\n",
            " ['img_326615167456459758.jpg' 1]\n",
            " ['img_7942817984992492772.jpg' 2]\n",
            " ['img_7654323251272021270.jpg' 1]\n",
            " ['img_7173963727515602195.jpg' 2]\n",
            " ['img_6169620279108166800.jpg' 2]\n",
            " ['img_855249587539445887.jpg' 1]\n",
            " ['img_794618938159923058.jpg' 1]\n",
            " ['img_8979905292764350675.jpg' 1]\n",
            " ['img_8280565345405706627.jpg' 2]\n",
            " ['img_1260586497798188644.jpg' 0]\n",
            " ['img_3595535600758445606.jpg' 2]\n",
            " ['img_6953780265806308912.jpg' 0]\n",
            " ['img_3154465148384084641.jpg' 0]\n",
            " ['img_5155911338932315832.jpg' 0]\n",
            " ['img_3566218207204430437.jpg' 1]\n",
            " ['img_6578720164735522405.jpg' 2]\n",
            " ['img_8701290738570089128.jpg' 1]\n",
            " ['img_3159895824686489556.jpg' 2]\n",
            " ['img_3334803466323212880.jpg' 0]\n",
            " ['img_1926749487122131462.jpg' 2]\n",
            " ['img_6210132542639847056.jpg' 2]\n",
            " ['img_4429272099376948196.jpg' 0]\n",
            " ['img_7190629333810912094.jpg' 0]\n",
            " ['img_5849387353655336882.jpg' 1]\n",
            " ['img_6141621420148581308.jpg' 2]\n",
            " ['img_4889663546054289277.jpg' 2]\n",
            " ['img_1037372824298815463.jpg' 1]\n",
            " ['img_8960730459389918564.jpg' 2]\n",
            " ['img_8828699246966569988.jpg' 0]\n",
            " ['img_1477479086216980236.jpg' 2]\n",
            " ['img_1833388785280856316.jpg' 1]\n",
            " ['img_1713224163938910130.jpg' 0]\n",
            " ['img_4407798448601164695.jpg' 0]\n",
            " ['img_3035966743001939252.jpg' 1]\n",
            " ['img_2943701944774712602.jpg' 0]\n",
            " ['img_3216576266432202415.jpg' 1]\n",
            " ['img_8905474884961559932.jpg' 2]\n",
            " ['img_810137399300732975.jpg' 0]\n",
            " ['img_2492490858331677509.jpg' 2]\n",
            " ['img_4434471664760107351.jpg' 0]\n",
            " ['img_2643033790342519090.jpg' 2]\n",
            " ['img_16543453932950536.jpg' 0]\n",
            " ['img_7140756721751586104.jpg' 2]\n",
            " ['img_7626264850724698248.jpg' 2]\n",
            " ['img_4093835357336465285.jpg' 2]\n",
            " ['img_8084625924603455421.jpg' 2]\n",
            " ['img_8355851820648014689.jpg' 2]\n",
            " ['img_409784611879302770.jpg' 0]\n",
            " ['img_819367447881328753.jpg' 1]\n",
            " ['img_7315086912640737495.jpg' 0]\n",
            " ['img_2507610750886151852.jpg' 0]\n",
            " ['img_2908529418625952020.jpg' 2]\n",
            " ['img_5201551205611804883.jpg' 0]\n",
            " ['img_5479284594075325803.jpg' 2]\n",
            " ['img_3466989037577033284.jpg' 2]\n",
            " ['img_5272943538320500041.jpg' 1]\n",
            " ['img_3314582950949657844.jpg' 0]\n",
            " ['img_850554561970506006.jpg' 0]\n",
            " ['img_3773844652795798034.jpg' 2]\n",
            " ['img_679570295353708576.jpg' 1]\n",
            " ['img_1534137222001388930.jpg' 2]\n",
            " ['img_7257483060246601206.jpg' 0]\n",
            " ['img_3824805790738967014.jpg' 0]\n",
            " ['img_9044131109755317189.jpg' 1]\n",
            " ['img_1131369692869272887.jpg' 1]\n",
            " ['img_1679165402137466289.jpg' 1]\n",
            " ['img_1744352442018228065.jpg' 0]\n",
            " ['img_2516468205804734036.jpg' 2]\n",
            " ['img_7604691481558121853.jpg' 0]\n",
            " ['img_8788481534666202057.jpg' 1]\n",
            " ['img_1082179150533558647.jpg' 0]\n",
            " ['img_7207120539432869321.jpg' 0]\n",
            " ['img_4762413671186156023.jpg' 2]\n",
            " ['img_1055155538793908277.jpg' 0]\n",
            " ['img_5515251430626804049.jpg' 2]\n",
            " ['img_8052643753161129661.jpg' 2]\n",
            " ['img_1771961916908629954.jpg' 1]\n",
            " ['img_2320414955148921779.jpg' 1]\n",
            " ['img_1102208210595046337.jpg' 1]\n",
            " ['img_6947398737754467351.jpg' 1]\n",
            " ['img_2022847705926062424.jpg' 0]\n",
            " ['img_342677409649899086.jpg' 1]\n",
            " ['img_4735349276668709504.jpg' 0]\n",
            " ['img_7280471905416714730.jpg' 2]\n",
            " ['img_7464724273126238623.jpg' 1]\n",
            " ['img_362525932448338715.jpg' 1]\n",
            " ['img_8028950582200808621.jpg' 0]\n",
            " ['img_1223654159476859553.jpg' 0]\n",
            " ['img_8504933298998865069.jpg' 0]\n",
            " ['img_2986132742682447499.jpg' 1]\n",
            " ['img_4828162915137280106.jpg' 0]\n",
            " ['img_5831477303531145918.jpg' 0]\n",
            " ['img_1490474487487535819.jpg' 0]\n",
            " ['img_6646563203582443874.jpg' 0]\n",
            " ['img_195555606680801741.jpg' 0]\n",
            " ['img_795053785833057775.jpg' 1]\n",
            " ['img_2533741230253651031.jpg' 1]\n",
            " ['img_993379363720995255.jpg' 1]\n",
            " ['img_8507570844526144584.jpg' 1]\n",
            " ['img_2861052939359538760.jpg' 1]\n",
            " ['img_8447650769081832149.jpg' 0]\n",
            " ['img_458362613942216499.jpg' 0]\n",
            " ['img_1981190917350755592.jpg' 0]\n",
            " ['img_9063081516357158199.jpg' 1]\n",
            " ['img_3734353936240333454.jpg' 2]\n",
            " ['img_8641421948669256805.jpg' 0]\n",
            " ['img_6045635867396666998.jpg' 1]\n",
            " ['img_5832378605261537556.jpg' 0]\n",
            " ['img_2382054298179923448.jpg' 1]\n",
            " ['img_7396216923565058910.jpg' 0]\n",
            " ['img_965014626488754880.jpg' 2]\n",
            " ['img_1870506046674880480.jpg' 0]\n",
            " ['img_4317934213726666089.jpg' 1]\n",
            " ['img_6781690177847530866.jpg' 2]\n",
            " ['img_2718863961462415587.jpg' 0]\n",
            " ['img_6615222649022061074.jpg' 1]\n",
            " ['img_5168852256496568902.jpg' 1]\n",
            " ['img_1948560918556519608.jpg' 0]\n",
            " ['img_7250572414191838877.jpg' 0]\n",
            " ['img_4521876800023462238.jpg' 1]\n",
            " ['img_6823945810269271557.jpg' 1]\n",
            " ['img_4782590793984928241.jpg' 0]\n",
            " ['img_5203881012087288598.jpg' 1]\n",
            " ['img_7268272383967734935.jpg' 1]\n",
            " ['img_309748544375083396.jpg' 2]\n",
            " ['img_8160699551451325019.jpg' 1]\n",
            " ['img_6590483531311685677.jpg' 1]\n",
            " ['img_4987624439250701810.jpg' 0]\n",
            " ['img_5391277730917613268.jpg' 0]\n",
            " ['img_95366251830285326.jpg' 2]\n",
            " ['img_3625994970728835824.jpg' 1]\n",
            " ['img_5246297716436319185.jpg' 0]\n",
            " ['img_4988423213753688381.jpg' 1]\n",
            " ['img_2360135580290197321.jpg' 0]\n",
            " ['img_7949620139104128779.jpg' 0]\n",
            " ['img_9059612294556593638.jpg' 0]\n",
            " ['img_97840054331160257.jpg' 0]\n",
            " ['img_3477823148596660297.jpg' 0]\n",
            " ['img_2047366509989882925.jpg' 2]\n",
            " ['img_530182487742229132.jpg' 1]\n",
            " ['img_4927539477836221461.jpg' 1]\n",
            " ['img_5178803844564390785.jpg' 0]\n",
            " ['img_7140015325142291641.jpg' 2]\n",
            " ['img_6833567210786375222.jpg' 2]\n",
            " ['img_1799445223247962919.jpg' 1]\n",
            " ['img_8778812012436885773.jpg' 1]\n",
            " ['img_6133304386858763579.jpg' 1]\n",
            " ['img_4644033119340155429.jpg' 1]\n",
            " ['img_4797366903286387565.jpg' 0]\n",
            " ['img_5612873399003633905.jpg' 1]\n",
            " ['img_6184984162130481171.jpg' 0]\n",
            " ['img_2803257049172627738.jpg' 2]\n",
            " ['img_7241224584347820565.jpg' 0]\n",
            " ['img_6621753007480786998.jpg' 1]\n",
            " ['img_5920432535359471348.jpg' 0]\n",
            " ['img_5498164663122290812.jpg' 0]\n",
            " ['img_6579917380666076398.jpg' 0]\n",
            " ['img_6732387063597663432.jpg' 0]\n",
            " ['img_5613329602337145070.jpg' 0]\n",
            " ['img_2396600103975105995.jpg' 2]\n",
            " ['img_5021090843935706343.jpg' 0]\n",
            " ['img_8086638699825215866.jpg' 1]\n",
            " ['img_3660947182077712033.jpg' 1]\n",
            " ['img_3365402587016859517.jpg' 0]\n",
            " ['img_1581826477875631396.jpg' 1]\n",
            " ['img_1943907923729424287.jpg' 2]\n",
            " ['img_7201843388805359804.jpg' 0]\n",
            " ['img_2784676729589669706.jpg' 0]\n",
            " ['img_6999497865857730892.jpg' 1]\n",
            " ['img_7665142896360300883.jpg' 0]\n",
            " ['img_6782707518318608182.jpg' 1]\n",
            " ['img_5426868056185555434.jpg' 2]\n",
            " ['img_1507042760809194251.jpg' 0]\n",
            " ['img_1685050764950792505.jpg' 1]\n",
            " ['img_1129866115399804592.jpg' 1]\n",
            " ['img_8338891436796831755.jpg' 2]\n",
            " ['img_4927611940165274668.jpg' 0]\n",
            " ['img_2693175790939458666.jpg' 1]\n",
            " ['img_6586608220492939302.jpg' 0]\n",
            " ['img_6203645195185657541.jpg' 0]\n",
            " ['img_5373952509616974647.jpg' 2]\n",
            " ['img_5383835205105850074.jpg' 0]\n",
            " ['img_757213804825186199.jpg' 2]\n",
            " ['img_5288165528057613015.jpg' 2]\n",
            " ['img_7698324050256402722.jpg' 0]\n",
            " ['img_291456191912412269.jpg' 0]\n",
            " ['img_1375125160918996040.jpg' 0]\n",
            " ['img_494371365535313240.jpg' 0]\n",
            " ['img_4835514472222572510.jpg' 2]\n",
            " ['img_3847094662067766065.jpg' 0]\n",
            " ['img_4728314211644704333.jpg' 1]\n",
            " ['img_591809710569472205.jpg' 1]\n",
            " ['img_1966841119723902749.jpg' 0]\n",
            " ['img_6327088759276735919.jpg' 2]\n",
            " ['img_1292614197918388809.jpg' 2]\n",
            " ['img_5676877461276025484.jpg' 2]\n",
            " ['img_4364406999685006438.jpg' 0]\n",
            " ['img_132024516253214402.jpg' 2]\n",
            " ['img_8491892713577199590.jpg' 2]\n",
            " ['img_6009378015578239286.jpg' 0]\n",
            " ['img_1193530292025631274.jpg' 1]\n",
            " ['img_4092565227645487533.jpg' 0]\n",
            " ['img_7839106638283213072.jpg' 1]\n",
            " ['img_5936353254203590884.jpg' 1]\n",
            " ['img_5038024617583270238.jpg' 2]\n",
            " ['img_4305679400920953348.jpg' 1]\n",
            " ['img_8970234790631534257.jpg' 0]\n",
            " ['img_6686470047331051628.jpg' 0]\n",
            " ['img_938575128184942645.jpg' 1]\n",
            " ['img_7622010737203052772.jpg' 0]\n",
            " ['img_6097556937695977194.jpg' 2]\n",
            " ['img_934502889134425254.jpg' 1]\n",
            " ['img_1257200206508103767.jpg' 1]\n",
            " ['img_9106031125108034285.jpg' 2]\n",
            " ['img_7295556701733174135.jpg' 1]\n",
            " ['img_7834116527351732213.jpg' 1]\n",
            " ['img_8443507175630053507.jpg' 1]\n",
            " ['img_5309991785486751875.jpg' 1]\n",
            " ['img_4844632251299883159.jpg' 1]\n",
            " ['img_4054452918874199214.jpg' 2]\n",
            " ['img_5912118068939857694.jpg' 1]\n",
            " ['img_8780333496565687234.jpg' 2]\n",
            " ['img_778421331240817588.jpg' 0]\n",
            " ['img_988137790593390154.jpg' 1]\n",
            " ['img_7687839792761503721.jpg' 1]\n",
            " ['img_3680503622682614400.jpg' 0]\n",
            " ['img_7532809220725119191.jpg' 0]\n",
            " ['img_4141945189726639573.jpg' 0]\n",
            " ['img_7784101631074235609.jpg' 2]\n",
            " ['img_6446052636971148987.jpg' 2]\n",
            " ['img_8618529911001041476.jpg' 1]\n",
            " ['img_524615481842685299.jpg' 1]\n",
            " ['img_8965547881640213283.jpg' 1]\n",
            " ['img_6613088707356375301.jpg' 1]\n",
            " ['img_6046627926984001756.jpg' 2]\n",
            " ['img_759681940562630425.jpg' 1]\n",
            " ['img_7820389474101636039.jpg' 2]\n",
            " ['img_7134569366192442276.jpg' 2]\n",
            " ['img_2877518928984196656.jpg' 0]\n",
            " ['img_4209854190008302544.jpg' 2]\n",
            " ['img_3915527803628498983.jpg' 1]\n",
            " ['img_7830377984822826547.jpg' 1]\n",
            " ['img_3043232650265081515.jpg' 2]\n",
            " ['img_195541082938233629.jpg' 1]\n",
            " ['img_2187896032555002978.jpg' 2]\n",
            " ['img_7977432292103192630.jpg' 1]\n",
            " ['img_2368775243358230299.jpg' 0]\n",
            " ['img_8262331439659703226.jpg' 1]\n",
            " ['img_8412025007399486083.jpg' 2]\n",
            " ['img_5441556622681351560.jpg' 2]\n",
            " ['img_8458387885205527945.jpg' 2]\n",
            " ['img_3670186102528301704.jpg' 2]\n",
            " ['img_3821895104547740369.jpg' 1]\n",
            " ['img_6542973348887412733.jpg' 1]\n",
            " ['img_3947017959138264926.jpg' 2]\n",
            " ['img_9041102629474061625.jpg' 1]\n",
            " ['img_6137607128116106911.jpg' 2]\n",
            " ['img_4215841064136899435.jpg' 0]\n",
            " ['img_8617392473030031382.jpg' 1]\n",
            " ['img_1307931683460582151.jpg' 2]\n",
            " ['img_4440304878817019691.jpg' 1]\n",
            " ['img_5158349335238120178.jpg' 2]\n",
            " ['img_2003769168895375749.jpg' 0]\n",
            " ['img_1572898237704842791.jpg' 2]\n",
            " ['img_7263989080063621968.jpg' 1]\n",
            " ['img_7272203759258805733.jpg' 2]\n",
            " ['img_3981621149177049142.jpg' 2]\n",
            " ['img_6428856454086462367.jpg' 2]\n",
            " ['img_4378769463251059185.jpg' 0]\n",
            " ['img_5003097674576373793.jpg' 0]\n",
            " ['img_4240977948464073319.jpg' 0]\n",
            " ['img_8792915508428436871.jpg' 0]\n",
            " ['img_6744903722458171428.jpg' 2]\n",
            " ['img_9056846072161814641.jpg' 2]\n",
            " ['img_7754104607702487343.jpg' 1]\n",
            " ['img_7708817198802112265.jpg' 1]\n",
            " ['img_2940720971083876333.jpg' 1]\n",
            " ['img_646486425530070171.jpg' 1]\n",
            " ['img_4413849550221994865.jpg' 2]\n",
            " ['img_5628306679788705325.jpg' 0]\n",
            " ['img_2112997954105399091.jpg' 1]\n",
            " ['img_3210782736081292315.jpg' 0]\n",
            " ['img_1375898345233961566.jpg' 0]\n",
            " ['img_7350453908244863586.jpg' 1]\n",
            " ['img_3224358615716716602.jpg' 2]\n",
            " ['img_1716840671210853250.jpg' 1]\n",
            " ['img_6115964904193359419.jpg' 1]\n",
            " ['img_7420995378403748237.jpg' 1]\n",
            " ['img_8896367615570936529.jpg' 1]\n",
            " ['img_2057167101184612438.jpg' 1]\n",
            " ['img_6392026896820342525.jpg' 0]\n",
            " ['img_5590629088364984140.jpg' 0]\n",
            " ['img_1162351550721440578.jpg' 1]\n",
            " ['img_3450630962337068758.jpg' 1]\n",
            " ['img_2736792499786708293.jpg' 1]\n",
            " ['img_6103075809942071744.jpg' 1]\n",
            " ['img_2356832399076584752.jpg' 0]\n",
            " ['img_494849520962832034.jpg' 1]\n",
            " ['img_8753874102118831096.jpg' 1]\n",
            " ['img_3459743985653004915.jpg' 0]\n",
            " ['img_1294845672711394260.jpg' 0]\n",
            " ['img_8001667574034052937.jpg' 1]\n",
            " ['img_3380738016831216149.jpg' 1]\n",
            " ['img_89674115523456831.jpg' 2]\n",
            " ['img_1084571077180415795.jpg' 1]\n",
            " ['img_2306817743164878111.jpg' 2]\n",
            " ['img_3389889408287623708.jpg' 0]\n",
            " ['img_8110058401461457049.jpg' 0]\n",
            " ['img_3284799031684833562.jpg' 0]\n",
            " ['img_6825188252425573258.jpg' 1]\n",
            " ['img_6980965631931299285.jpg' 1]\n",
            " ['img_8389870076312118712.jpg' 0]\n",
            " ['img_6303110881180341133.jpg' 1]\n",
            " ['img_877133537661717168.jpg' 0]\n",
            " ['img_8545573981214497993.jpg' 1]\n",
            " ['img_5776832597968882042.jpg' 0]\n",
            " ['img_5073782047150167219.jpg' 2]\n",
            " ['img_7908958329087360696.jpg' 2]\n",
            " ['img_4459747127597389193.jpg' 0]\n",
            " ['img_7230829381665638374.jpg' 1]\n",
            " ['img_6223120209796517638.jpg' 1]\n",
            " ['img_6253237329017744830.jpg' 1]\n",
            " ['img_5459263846227846108.jpg' 1]\n",
            " ['img_4113552116817501941.jpg' 0]\n",
            " ['img_7357091947805153414.jpg' 0]\n",
            " ['img_2340388818075626261.jpg' 1]\n",
            " ['img_9153201897976859454.jpg' 1]\n",
            " ['img_4380579010623871421.jpg' 2]\n",
            " ['img_5618988086293803776.jpg' 1]\n",
            " ['img_8616834392729241196.jpg' 2]\n",
            " ['img_3039969317730652544.jpg' 1]\n",
            " ['img_1945074002506083740.jpg' 0]\n",
            " ['img_1496593934902352483.jpg' 0]\n",
            " ['img_8513530723612166706.jpg' 0]\n",
            " ['img_1955031036267293474.jpg' 1]\n",
            " ['img_1393298377401141978.jpg' 0]\n",
            " ['img_6608524604567203294.jpg' 0]\n",
            " ['img_7527747328472957352.jpg' 0]\n",
            " ['img_8745817965658644348.jpg' 0]\n",
            " ['img_4537635137830942841.jpg' 1]\n",
            " ['img_3889631731843541390.jpg' 1]\n",
            " ['img_2832488693241428617.jpg' 0]\n",
            " ['img_8140656618048755045.jpg' 0]\n",
            " ['img_6383224598737078418.jpg' 0]\n",
            " ['img_5384561405482415838.jpg' 2]\n",
            " ['img_9039429759043125546.jpg' 0]\n",
            " ['img_4208708048630350397.jpg' 2]\n",
            " ['img_5470466521014718746.jpg' 0]\n",
            " ['img_3033699276614193285.jpg' 2]\n",
            " ['img_7434320979519517220.jpg' 1]\n",
            " ['img_5891091982226048757.jpg' 1]\n",
            " ['img_3671297681850645907.jpg' 1]\n",
            " ['img_1313472066269212275.jpg' 0]\n",
            " ['img_4063990277791674240.jpg' 1]\n",
            " ['img_3624338488442470581.jpg' 1]\n",
            " ['img_4736177860702885402.jpg' 0]\n",
            " ['img_7983616275220441454.jpg' 2]\n",
            " ['img_6725394313952790956.jpg' 0]\n",
            " ['img_3082643519457778063.jpg' 0]\n",
            " ['img_1735601789454160338.jpg' 1]\n",
            " ['img_6992560318799549670.jpg' 1]\n",
            " ['img_4133282246843365186.jpg' 0]\n",
            " ['img_2304152176206178387.jpg' 1]\n",
            " ['img_4286769936590868906.jpg' 1]\n",
            " ['img_4756776386322473377.jpg' 0]\n",
            " ['img_7034460685415683872.jpg' 2]\n",
            " ['img_206651298953027095.jpg' 1]\n",
            " ['img_4966818476649438052.jpg' 1]\n",
            " ['img_8518105958456289580.jpg' 2]\n",
            " ['img_4728051070197368741.jpg' 0]\n",
            " ['img_4505362360844926793.jpg' 1]\n",
            " ['img_6028488180981950754.jpg' 1]\n",
            " ['img_8356867863649128611.jpg' 1]\n",
            " ['img_6790189411645202346.jpg' 0]\n",
            " ['img_2323510701716878093.jpg' 1]\n",
            " ['img_293159259361756326.jpg' 2]\n",
            " ['img_5919503744088091377.jpg' 1]\n",
            " ['img_2291531898193798073.jpg' 0]\n",
            " ['img_5818202878987656545.jpg' 1]\n",
            " ['img_4588594959761584193.jpg' 2]\n",
            " ['img_5436530181599969979.jpg' 1]\n",
            " ['img_8166241493062500339.jpg' 2]\n",
            " ['img_5946310119066144969.jpg' 0]\n",
            " ['img_491708567904600647.jpg' 0]\n",
            " ['img_8551650419866924335.jpg' 2]\n",
            " ['img_8793178977556944902.jpg' 1]\n",
            " ['img_6514344060099583558.jpg' 0]\n",
            " ['img_7695101125737889067.jpg' 1]\n",
            " ['img_3370954735302474020.jpg' 1]\n",
            " ['img_7555203929475358149.jpg' 0]\n",
            " ['img_591584801783401073.jpg' 2]\n",
            " ['img_5677501101896248575.jpg' 2]\n",
            " ['img_5091209113774303713.jpg' 0]\n",
            " ['img_8416056474189944792.jpg' 0]\n",
            " ['img_931568982072680605.jpg' 1]\n",
            " ['img_3175378979857356905.jpg' 0]\n",
            " ['img_6577013989161202594.jpg' 0]\n",
            " ['img_1046182996541873496.jpg' 0]\n",
            " ['img_4502832984664005117.jpg' 0]\n",
            " ['img_3711501422875845749.jpg' 1]\n",
            " ['img_3623158057843212757.jpg' 1]\n",
            " ['img_7428283349299384403.jpg' 0]\n",
            " ['img_5783584904439060764.jpg' 1]\n",
            " ['img_4259526646234895114.jpg' 1]\n",
            " ['img_1498425366667951032.jpg' 0]\n",
            " ['img_1887006490272584483.jpg' 0]\n",
            " ['img_257902381790461453.jpg' 0]\n",
            " ['img_5870943223354015472.jpg' 0]\n",
            " ['img_1063539320518541645.jpg' 1]\n",
            " ['img_463088749951869556.jpg' 0]\n",
            " ['img_7591753064969946590.jpg' 0]\n",
            " ['img_6817656625049982106.jpg' 1]\n",
            " ['img_8593137312041065301.jpg' 0]\n",
            " ['img_4499712089765304345.jpg' 2]\n",
            " ['img_8942144831274036532.jpg' 2]\n",
            " ['img_690306978935196800.jpg' 1]\n",
            " ['img_5194205737478096368.jpg' 1]\n",
            " ['img_1593948901524536090.jpg' 2]\n",
            " ['img_9055447089309368165.jpg' 0]\n",
            " ['img_4287387257817386048.jpg' 0]\n",
            " ['img_1448150965069194240.jpg' 1]\n",
            " ['img_1369081416880556913.jpg' 0]\n",
            " ['img_4053080509161894087.jpg' 0]\n",
            " ['img_6037727293675187094.jpg' 0]\n",
            " ['img_2137371062114920132.jpg' 0]\n",
            " ['img_6101854963174836109.jpg' 1]\n",
            " ['img_2934141282533211963.jpg' 0]\n",
            " ['img_2442275678058911283.jpg' 0]\n",
            " ['img_8819449935048793427.jpg' 0]\n",
            " ['img_7597604912234176155.jpg' 0]\n",
            " ['img_5898977501241964847.jpg' 0]\n",
            " ['img_1577483589017807754.jpg' 0]\n",
            " ['img_9119068252431996837.jpg' 0]\n",
            " ['img_5436748757903597082.jpg' 0]\n",
            " ['img_5284868688688261886.jpg' 2]\n",
            " ['img_1922082027129315425.jpg' 0]\n",
            " ['img_7407613427699783666.jpg' 0]\n",
            " ['img_5892792640854117727.jpg' 1]\n",
            " ['img_4631306166365896761.jpg' 0]\n",
            " ['img_2476693347233056446.jpg' 1]\n",
            " ['img_8910557226104159684.jpg' 0]\n",
            " ['img_3498000132500477696.jpg' 0]\n",
            " ['img_9036007147622061008.jpg' 0]\n",
            " ['img_3638374421002637065.jpg' 0]\n",
            " ['img_524742468982487059.jpg' 1]\n",
            " ['img_6720177507584485211.jpg' 0]\n",
            " ['img_8531789453034878258.jpg' 0]\n",
            " ['img_5782807694557165338.jpg' 0]\n",
            " ['img_8272857328299176612.jpg' 0]\n",
            " ['img_6299325830668672642.jpg' 0]\n",
            " ['img_6401479569723369331.jpg' 1]\n",
            " ['img_2959012695146593880.jpg' 0]\n",
            " ['img_7155141019934768416.jpg' 1]\n",
            " ['img_4434192015477037226.jpg' 0]\n",
            " ['img_8779915903044380997.jpg' 0]\n",
            " ['img_8688021515572444900.jpg' 0]\n",
            " ['img_2871419426160856350.jpg' 2]\n",
            " ['img_707962121600310035.jpg' 0]\n",
            " ['img_3477497286790766870.jpg' 0]\n",
            " ['img_6430939848650792518.jpg' 1]\n",
            " ['img_3923878152534577762.jpg' 0]\n",
            " ['img_4888278351847574589.jpg' 0]\n",
            " ['img_8707718323773179690.jpg' 0]\n",
            " ['img_3814134044511002188.jpg' 0]\n",
            " ['img_784833703528481209.jpg' 1]\n",
            " ['img_2278177160359080723.jpg' 1]\n",
            " ['img_462231663443518942.jpg' 1]\n",
            " ['img_9194791048109031988.jpg' 1]\n",
            " ['img_3356889156538712853.jpg' 0]\n",
            " ['img_952926752100725623.jpg' 0]\n",
            " ['img_4085870517142676801.jpg' 0]\n",
            " ['img_5600140410771651559.jpg' 0]\n",
            " ['img_1645044193150430179.jpg' 0]\n",
            " ['img_3280410357500188652.jpg' 0]\n",
            " ['img_3173938023491699053.jpg' 0]\n",
            " ['img_555657553443958724.jpg' 0]\n",
            " ['img_5394660408565286290.jpg' 1]\n",
            " ['img_4475118317276893185.jpg' 1]\n",
            " ['img_1825895554685637076.jpg' 0]\n",
            " ['img_8393016019675458091.jpg' 2]\n",
            " ['img_2240078762518333441.jpg' 0]\n",
            " ['img_2318304129563734977.jpg' 0]\n",
            " ['img_2467263834691498367.jpg' 0]\n",
            " ['img_4360840785536661566.jpg' 0]\n",
            " ['img_3942602063359373013.jpg' 0]\n",
            " ['img_2683080004896533266.jpg' 0]\n",
            " ['img_3695465628621925702.jpg' 1]\n",
            " ['img_4365253913092295326.jpg' 0]\n",
            " ['img_8263976050993954004.jpg' 0]\n",
            " ['img_4347510300803380303.jpg' 0]\n",
            " ['img_3319985519744237007.jpg' 1]\n",
            " ['img_3564823316432238687.jpg' 0]\n",
            " ['img_7821203529477400248.jpg' 0]\n",
            " ['img_4312814829295633357.jpg' 2]\n",
            " ['img_2362687453971827126.jpg' 0]\n",
            " ['img_7712270390655694987.jpg' 1]\n",
            " ['img_1342074365281554838.jpg' 2]\n",
            " ['img_6874210929497858068.jpg' 1]\n",
            " ['img_5177932409177189440.jpg' 1]\n",
            " ['img_7063399721294221861.jpg' 0]\n",
            " ['img_8750042489641602691.jpg' 1]\n",
            " ['img_1659310664085353176.jpg' 0]\n",
            " ['img_6512079352877968869.jpg' 0]\n",
            " ['img_6023658657512611645.jpg' 1]\n",
            " ['img_5264414874326115317.jpg' 0]\n",
            " ['img_1056493789828791097.jpg' 1]\n",
            " ['img_1784196001721965078.jpg' 1]\n",
            " ['img_1123863876791783558.jpg' 2]\n",
            " ['img_2635219978556036282.jpg' 2]\n",
            " ['img_6217615297456853705.jpg' 0]\n",
            " ['img_6702264776212918694.jpg' 0]\n",
            " ['img_8584730734538968119.jpg' 1]\n",
            " ['img_9013585571058568187.jpg' 2]\n",
            " ['img_6078291590311419118.jpg' 0]\n",
            " ['img_3902201439835711221.jpg' 2]\n",
            " ['img_4228900950557541137.jpg' 2]\n",
            " ['img_1202297022976410281.jpg' 2]\n",
            " ['img_5983951325140220932.jpg' 1]\n",
            " ['img_1801460138122924679.jpg' 1]\n",
            " ['img_4194388178521315004.jpg' 0]\n",
            " ['img_1069295317302009938.jpg' 0]\n",
            " ['img_5330373439936371934.jpg' 0]\n",
            " ['img_8297091940650672230.jpg' 0]\n",
            " ['img_6710234190652032746.jpg' 1]\n",
            " ['img_7935076390612106143.jpg' 2]\n",
            " ['img_8903448479478801931.jpg' 0]\n",
            " ['img_7142131290768421504.jpg' 0]\n",
            " ['img_5812537591474627815.jpg' 0]\n",
            " ['img_4118304235328063247.jpg' 0]\n",
            " ['img_7015465075788174380.jpg' 0]\n",
            " ['img_7747912208700225262.jpg' 1]\n",
            " ['img_9095186451697361207.jpg' 0]\n",
            " ['img_3959267384940363423.jpg' 1]\n",
            " ['img_4258829299898861673.jpg' 0]\n",
            " ['img_16782448840619509.jpg' 0]\n",
            " ['img_8809571618191250823.jpg' 2]\n",
            " ['img_4272375777655862608.jpg' 0]\n",
            " ['img_2693747451325536665.jpg' 0]\n",
            " ['img_261172294825194086.jpg' 0]\n",
            " ['img_419677153032489544.jpg' 1]\n",
            " ['img_3593757190479507126.jpg' 0]\n",
            " ['img_5494896988022442226.jpg' 0]\n",
            " ['img_1005556732793955351.jpg' 0]\n",
            " ['img_4849413997639043562.jpg' 1]\n",
            " ['img_4070089355300977875.jpg' 2]\n",
            " ['img_7741276816232889008.jpg' 2]\n",
            " ['img_2583219412662900677.jpg' 1]\n",
            " ['img_2745266601947275658.jpg' 0]\n",
            " ['img_2608362305198281193.jpg' 1]\n",
            " ['img_8991655775025057190.jpg' 0]\n",
            " ['img_8069904621400231968.jpg' 2]\n",
            " ['img_5044651256379642188.jpg' 0]\n",
            " ['img_867415519208706542.jpg' 0]\n",
            " ['img_2655342918202865468.jpg' 1]\n",
            " ['img_7897349324930675394.jpg' 1]\n",
            " ['img_268743828474932122.jpg' 0]\n",
            " ['img_3768514485206857075.jpg' 0]\n",
            " ['img_3779706458979858995.jpg' 1]\n",
            " ['img_4717089755786131171.jpg' 0]\n",
            " ['img_4230733552669831057.jpg' 2]\n",
            " ['img_3070917141581823274.jpg' 0]\n",
            " ['img_6895900425903742985.jpg' 2]\n",
            " ['img_5342619022318820729.jpg' 0]\n",
            " ['img_8538463596046919950.jpg' 2]\n",
            " ['img_8971276851277793539.jpg' 2]\n",
            " ['img_8221922465625403953.jpg' 2]\n",
            " ['img_2335375268872105223.jpg' 2]\n",
            " ['img_6719353063912861195.jpg' 0]\n",
            " ['img_3399441121006194784.jpg' 1]\n",
            " ['img_4572607651551309041.jpg' 0]\n",
            " ['img_3157147901018424236.jpg' 2]\n",
            " ['img_3613104037031425403.jpg' 1]\n",
            " ['img_8467110483817049658.jpg' 0]\n",
            " ['img_5714712301509268799.jpg' 2]\n",
            " ['img_7773997472647562996.jpg' 1]\n",
            " ['img_178073747713010800.jpg' 0]\n",
            " ['img_520484574766711796.jpg' 1]\n",
            " ['img_2317588609863354672.jpg' 1]\n",
            " ['img_3329618818944080044.jpg' 1]\n",
            " ['img_7330294143171041514.jpg' 1]\n",
            " ['img_3117561317167988973.jpg' 1]\n",
            " ['img_8494466323726677698.jpg' 1]\n",
            " ['img_8862463692130080924.jpg' 2]\n",
            " ['img_8053119952864758580.jpg' 1]\n",
            " ['img_7987610849951500780.jpg' 1]\n",
            " ['img_5827867423774144246.jpg' 1]\n",
            " ['img_6541582638579367435.jpg' 1]\n",
            " ['img_2089438224520908039.jpg' 1]\n",
            " ['img_1947126793031742593.jpg' 1]\n",
            " ['img_8505589410649278167.jpg' 1]\n",
            " ['img_6538402239063112392.jpg' 1]\n",
            " ['img_28481234786363121.jpg' 2]\n",
            " ['img_7402664755295713979.jpg' 1]\n",
            " ['img_2171184104228445503.jpg' 1]\n",
            " ['img_14032172033196573.jpg' 1]\n",
            " ['img_5598951232128441896.jpg' 1]\n",
            " ['img_3845914366011000562.jpg' 1]\n",
            " ['img_809333700314128174.jpg' 1]\n",
            " ['img_4256285723757025097.jpg' 2]\n",
            " ['img_4206332349505852592.jpg' 1]\n",
            " ['img_4973568455899548036.jpg' 2]\n",
            " ['img_6681810814130963022.jpg' 1]\n",
            " ['img_7437153272678968461.jpg' 1]\n",
            " ['img_3646935997231839064.jpg' 2]\n",
            " ['img_5667291147277507935.jpg' 1]\n",
            " ['img_8192337674765663719.jpg' 1]\n",
            " ['img_29315399747303594.jpg' 1]\n",
            " ['img_5457620166515889096.jpg' 1]\n",
            " ['img_6116177289254115305.jpg' 1]\n",
            " ['img_5664887713142004415.jpg' 2]\n",
            " ['img_159167644943409549.jpg' 1]\n",
            " ['img_4210827799607299908.jpg' 1]\n",
            " ['img_6525200416149273469.jpg' 1]\n",
            " ['img_3123041884251940201.jpg' 0]\n",
            " ['img_486752523773746701.jpg' 1]\n",
            " ['img_8680083094043515250.jpg' 2]\n",
            " ['img_2591917604376605276.jpg' 2]\n",
            " ['img_7299210562610002776.jpg' 1]\n",
            " ['img_1219280710752744599.jpg' 1]\n",
            " ['img_5543635705221945395.jpg' 1]\n",
            " ['img_226614577145440113.jpg' 2]\n",
            " ['img_7069035479493288501.jpg' 1]\n",
            " ['img_8076958405607713303.jpg' 1]\n",
            " ['img_7231127042848917754.jpg' 2]\n",
            " ['img_3147234451603458360.jpg' 1]\n",
            " ['img_7852870843269061284.jpg' 1]\n",
            " ['img_3521027480856248907.jpg' 2]\n",
            " ['img_4586127375882805751.jpg' 1]\n",
            " ['img_1449475669828948362.jpg' 2]\n",
            " ['img_642280153758173247.jpg' 1]\n",
            " ['img_9033402981857143691.jpg' 1]\n",
            " ['img_2896066875511570074.jpg' 2]\n",
            " ['img_5057279161205239266.jpg' 1]\n",
            " ['img_2717475183485908591.jpg' 0]\n",
            " ['img_2942122175751391854.jpg' 1]\n",
            " ['img_8133940069064248170.jpg' 2]\n",
            " ['img_6446826890996649370.jpg' 1]\n",
            " ['img_4011991116160316543.jpg' 1]\n",
            " ['img_5923173764858070528.jpg' 1]\n",
            " ['img_5887711092052904393.jpg' 2]\n",
            " ['img_1330693339587696783.jpg' 2]\n",
            " ['img_958207799657787739.jpg' 2]\n",
            " ['img_8881768117019341900.jpg' 1]\n",
            " ['img_2407600172613439732.jpg' 1]\n",
            " ['img_1089446545260563550.jpg' 1]\n",
            " ['img_4068785523147349045.jpg' 1]\n",
            " ['img_4912167971517291239.jpg' 1]\n",
            " ['img_1135497390116745149.jpg' 1]\n",
            " ['img_77203601721027676.jpg' 1]\n",
            " ['img_7980218259402001162.jpg' 1]\n",
            " ['img_390441826544959386.jpg' 2]\n",
            " ['img_2437197590535329129.jpg' 2]\n",
            " ['img_8354204555257961492.jpg' 2]\n",
            " ['img_6523136768014325744.jpg' 2]\n",
            " ['img_3057480153425122570.jpg' 1]\n",
            " ['img_5016986998345864582.jpg' 1]\n",
            " ['img_6444359949778588441.jpg' 1]\n",
            " ['img_5292657170214141340.jpg' 1]\n",
            " ['img_5133563299230809972.jpg' 0]\n",
            " ['img_9087826998797326137.jpg' 1]\n",
            " ['img_246460783118233590.jpg' 2]\n",
            " ['img_6682403771030518737.jpg' 2]\n",
            " ['img_8706412932015725583.jpg' 2]\n",
            " ['img_4647920909202068310.jpg' 1]\n",
            " ['img_3028953756203864911.jpg' 1]\n",
            " ['img_7433725801764690644.jpg' 1]\n",
            " ['img_979022856541104117.jpg' 0]\n",
            " ['img_7318692627165465178.jpg' 2]\n",
            " ['img_9028910414878089373.jpg' 2]\n",
            " ['img_9100673805601003532.jpg' 1]\n",
            " ['img_7375076096500289234.jpg' 1]\n",
            " ['img_6544804688189569185.jpg' 1]\n",
            " ['img_1195977624644538766.jpg' 1]\n",
            " ['img_7220060562137170030.jpg' 1]\n",
            " ['img_6585785177324949074.jpg' 2]\n",
            " ['img_6167715900841317501.jpg' 1]\n",
            " ['img_8008431427699870129.jpg' 1]\n",
            " ['img_6770068618756603731.jpg' 1]\n",
            " ['img_2199902089400765895.jpg' 1]\n",
            " ['img_3879031927231402921.jpg' 2]\n",
            " ['img_843458659592018477.jpg' 2]\n",
            " ['img_3552710671353539050.jpg' 2]\n",
            " ['img_8257021531133070996.jpg' 2]\n",
            " ['img_4494213476305963686.jpg' 1]\n",
            " ['img_3603414223520585979.jpg' 2]\n",
            " ['img_870480192524648455.jpg' 2]\n",
            " ['img_7600759660807270241.jpg' 2]\n",
            " ['img_592500102174194481.jpg' 2]\n",
            " ['img_4402002412745724315.jpg' 1]\n",
            " ['img_1657280907627590335.jpg' 2]\n",
            " ['img_3315661826537366617.jpg' 1]\n",
            " ['img_321380087472575994.jpg' 1]\n",
            " ['img_3384618937685299234.jpg' 2]\n",
            " ['img_4377495946147888926.jpg' 2]\n",
            " ['img_2499384704820463906.jpg' 1]\n",
            " ['img_5299104358067570355.jpg' 1]\n",
            " ['img_2596149040038041925.jpg' 1]\n",
            " ['img_2814429647860663895.jpg' 2]\n",
            " ['img_4107146897174813352.jpg' 1]\n",
            " ['img_3272569786530857891.jpg' 0]\n",
            " ['img_1207853828423997041.jpg' 1]\n",
            " ['img_5957319981944982297.jpg' 1]\n",
            " ['img_7734619381718593433.jpg' 1]\n",
            " ['img_3710510190105456209.jpg' 2]\n",
            " ['img_6605895854051527332.jpg' 1]\n",
            " ['img_2095919889020652070.jpg' 1]\n",
            " ['img_1745977029246463972.jpg' 1]\n",
            " ['img_7862257251870748510.jpg' 1]\n",
            " ['img_8648730506064588343.jpg' 1]\n",
            " ['img_8535716105531977296.jpg' 1]\n",
            " ['img_1128297347845871447.jpg' 1]\n",
            " ['img_4011813843303997348.jpg' 2]\n",
            " ['img_4122808362499414639.jpg' 1]\n",
            " ['img_8960762134988038807.jpg' 1]\n",
            " ['img_7302198173139754457.jpg' 1]\n",
            " ['img_2252040634026791411.jpg' 2]\n",
            " ['img_7825529001995973090.jpg' 1]\n",
            " ['img_7893990447530481534.jpg' 1]\n",
            " ['img_489907737788850789.jpg' 1]\n",
            " ['img_2199808422466795515.jpg' 1]\n",
            " ['img_372617152869086281.jpg' 1]\n",
            " ['img_8725745564946082268.jpg' 1]\n",
            " ['img_874531081331856335.jpg' 1]\n",
            " ['img_5217262495495555389.jpg' 1]\n",
            " ['img_3028400972866003641.jpg' 2]\n",
            " ['img_1363141755756537527.jpg' 2]\n",
            " ['img_3734260242898440245.jpg' 1]\n",
            " ['img_880612644646283816.jpg' 0]\n",
            " ['img_2417890343363734326.jpg' 2]\n",
            " ['img_3279277272501545753.jpg' 1]\n",
            " ['img_6999327331854726579.jpg' 1]\n",
            " ['img_3680693842019239788.jpg' 2]\n",
            " ['img_6375702345016046862.jpg' 2]\n",
            " ['img_4666918256892998766.jpg' 2]\n",
            " ['img_3117634350947944515.jpg' 2]\n",
            " ['img_5153544189515314846.jpg' 1]\n",
            " ['img_1826130231820739247.jpg' 2]\n",
            " ['img_3895786885841601106.jpg' 1]\n",
            " ['img_1608884185818341737.jpg' 0]\n",
            " ['img_1962245183902349226.jpg' 2]\n",
            " ['img_6188871560367394911.jpg' 2]\n",
            " ['img_4445883447228389764.jpg' 1]\n",
            " ['img_6343674145577902797.jpg' 2]\n",
            " ['img_1880558547516617056.jpg' 2]\n",
            " ['img_333411196592719701.jpg' 2]\n",
            " ['img_4125532128317223185.jpg' 0]\n",
            " ['img_4637941172424867893.jpg' 1]\n",
            " ['img_2928666340313984967.jpg' 1]\n",
            " ['img_61039737729221886.jpg' 2]\n",
            " ['img_5081036521691149721.jpg' 2]\n",
            " ['img_5437279936734210652.jpg' 1]\n",
            " ['img_5454997456311542000.jpg' 1]\n",
            " ['img_6223728747785568595.jpg' 2]\n",
            " ['img_8241691682355650817.jpg' 1]\n",
            " ['img_801238669513743243.jpg' 1]\n",
            " ['img_5891946805705562146.jpg' 1]\n",
            " ['img_1844254636558483176.jpg' 1]\n",
            " ['img_5067074336466659726.jpg' 1]\n",
            " ['img_5776301289117191127.jpg' 1]\n",
            " ['img_8797626555359316715.jpg' 1]\n",
            " ['img_2020663387353028919.jpg' 1]\n",
            " ['img_5162247853265912844.jpg' 1]\n",
            " ['img_1289148150235016680.jpg' 1]\n",
            " ['img_4011598843874910470.jpg' 1]\n",
            " ['img_7293462608689823150.jpg' 1]\n",
            " ['img_3493145231110758533.jpg' 1]\n",
            " ['img_3599182012380150106.jpg' 1]\n",
            " ['img_8910362169042289061.jpg' 2]\n",
            " ['img_1237663687167431061.jpg' 1]\n",
            " ['img_5396107298440028943.jpg' 2]\n",
            " ['img_4630349681586486373.jpg' 1]\n",
            " ['img_4519018000728471691.jpg' 1]\n",
            " ['img_2350206155750504566.jpg' 1]\n",
            " ['img_514763219905256444.jpg' 2]\n",
            " ['img_8516618782170584580.jpg' 2]\n",
            " ['img_2912200739460365490.jpg' 1]\n",
            " ['img_4920539121350096941.jpg' 1]\n",
            " ['img_3297178019879999603.jpg' 1]\n",
            " ['img_8333316462076671710.jpg' 1]\n",
            " ['img_5621434814655479745.jpg' 0]\n",
            " ['img_325600650156244251.jpg' 1]\n",
            " ['img_4374570755579754760.jpg' 1]\n",
            " ['img_5223709372914414715.jpg' 1]\n",
            " ['img_745201720342534813.jpg' 1]\n",
            " ['img_8411225567982018092.jpg' 1]\n",
            " ['img_1303933482773577276.jpg' 1]\n",
            " ['img_388500633196748967.jpg' 1]\n",
            " ['img_9085138795147025469.jpg' 1]\n",
            " ['img_3716644453579351010.jpg' 0]\n",
            " ['img_1700411292978400415.jpg' 2]\n",
            " ['img_5667132343401775580.jpg' 1]\n",
            " ['img_4135189242450683211.jpg' 1]\n",
            " ['img_3437550885874062481.jpg' 1]\n",
            " ['img_1223018896484706644.jpg' 2]\n",
            " ['img_1067627733181002215.jpg' 1]\n",
            " ['img_5545025406621180326.jpg' 1]\n",
            " ['img_1571451043178677102.jpg' 1]\n",
            " ['img_5856969153653217975.jpg' 1]\n",
            " ['img_3384150148571933727.jpg' 2]\n",
            " ['img_6866331405420638757.jpg' 1]\n",
            " ['img_2749032654316716889.jpg' 2]\n",
            " ['img_8754410774634517532.jpg' 2]\n",
            " ['img_5034562330901059196.jpg' 1]\n",
            " ['img_3830484356417631742.jpg' 1]\n",
            " ['img_5727101654345440955.jpg' 1]\n",
            " ['img_4757839845663029061.jpg' 1]\n",
            " ['img_2730941378165080171.jpg' 1]\n",
            " ['img_3939563766016993775.jpg' 1]\n",
            " ['img_6455655908766701339.jpg' 0]\n",
            " ['img_1845364756671175313.jpg' 2]\n",
            " ['img_9218954439959078387.jpg' 1]\n",
            " ['img_6027560803114859517.jpg' 2]\n",
            " ['img_1013947992995844467.jpg' 2]\n",
            " ['img_8814869556548149507.jpg' 1]\n",
            " ['img_8474809725889468062.jpg' 1]\n",
            " ['img_3942823807439526615.jpg' 0]\n",
            " ['img_6338735137300693034.jpg' 1]\n",
            " ['img_9023453475727846449.jpg' 2]\n",
            " ['img_3874695416326313444.jpg' 1]\n",
            " ['img_7312301917168247961.jpg' 1]\n",
            " ['img_4270673995647908722.jpg' 1]\n",
            " ['img_3355716014516534477.jpg' 1]\n",
            " ['img_7278557422273578297.jpg' 1]\n",
            " ['img_8951139714240730249.jpg' 1]\n",
            " ['img_5902605490854339305.jpg' 1]\n",
            " ['img_5977880945810841573.jpg' 2]\n",
            " ['img_8761013394015635215.jpg' 1]\n",
            " ['img_7836259474847708041.jpg' 0]\n",
            " ['img_3436230621643290886.jpg' 1]\n",
            " ['img_8692156123179308853.jpg' 1]\n",
            " ['img_7889847314577988200.jpg' 1]\n",
            " ['img_7976757528914926414.jpg' 1]\n",
            " ['img_1895617167086345015.jpg' 1]\n",
            " ['img_1426330302722310710.jpg' 2]\n",
            " ['img_7807479097699367377.jpg' 2]\n",
            " ['img_1437796436977272856.jpg' 1]\n",
            " ['img_3226931574959824397.jpg' 2]\n",
            " ['img_5293067255333716383.jpg' 1]\n",
            " ['img_8103864271852431421.jpg' 1]\n",
            " ['img_1157894168738052107.jpg' 2]\n",
            " ['img_7664344612763514174.jpg' 1]\n",
            " ['img_180688085215986561.jpg' 2]\n",
            " ['img_3468267487440819570.jpg' 1]\n",
            " ['img_8001695473904100309.jpg' 2]\n",
            " ['img_3677462023884404764.jpg' 1]\n",
            " ['img_7152851990797879327.jpg' 1]\n",
            " ['img_1526160729051828615.jpg' 1]\n",
            " ['img_8351884345516805257.jpg' 1]\n",
            " ['img_6337432993793194670.jpg' 1]\n",
            " ['img_8342618782943593389.jpg' 1]\n",
            " ['img_769799271659639185.jpg' 2]\n",
            " ['img_4200064259179688039.jpg' 1]\n",
            " ['img_558848833200730523.jpg' 1]\n",
            " ['img_5735432678650248659.jpg' 2]\n",
            " ['img_6885702374453025731.jpg' 1]\n",
            " ['img_5222997202655640641.jpg' 1]\n",
            " ['img_3416890885902171587.jpg' 1]\n",
            " ['img_8752923950798397019.jpg' 0]\n",
            " ['img_3567023874635117119.jpg' 2]\n",
            " ['img_8085459959210444189.jpg' 1]\n",
            " ['img_8130247256951347236.jpg' 1]\n",
            " ['img_6107606320597104119.jpg' 1]\n",
            " ['img_571098891923495234.jpg' 1]\n",
            " ['img_4487448041291254851.jpg' 2]\n",
            " ['img_247184274838437145.jpg' 1]\n",
            " ['img_2205517802409050296.jpg' 1]\n",
            " ['img_7605384224045229395.jpg' 2]\n",
            " ['img_2703309632662161138.jpg' 1]\n",
            " ['img_7534476812375576419.jpg' 2]\n",
            " ['img_1523934492612473110.jpg' 2]\n",
            " ['img_930602723224365607.jpg' 1]\n",
            " ['img_3182181781120062177.jpg' 1]\n",
            " ['img_7105946721263286992.jpg' 2]\n",
            " ['img_6743516723034698722.jpg' 1]\n",
            " ['img_9206820654982296001.jpg' 2]\n",
            " ['img_2576702608870987.jpg' 0]\n",
            " ['img_5579374269253911843.jpg' 1]\n",
            " ['img_3968524495036039062.jpg' 2]\n",
            " ['img_5582659251984520633.jpg' 2]\n",
            " ['img_410447669972693818.jpg' 1]\n",
            " ['img_6524017123857861055.jpg' 1]\n",
            " ['img_1540470346968029424.jpg' 1]\n",
            " ['img_7554518551806006775.jpg' 1]\n",
            " ['img_1871789904921489751.jpg' 1]\n",
            " ['img_2619768779449980831.jpg' 2]\n",
            " ['img_2623272180078374718.jpg' 1]\n",
            " ['img_1380758563420969463.jpg' 1]\n",
            " ['img_4229421186515155413.jpg' 1]\n",
            " ['img_1545588471685841655.jpg' 1]\n",
            " ['img_4125403887231104203.jpg' 1]\n",
            " ['img_4072274720776314251.jpg' 1]\n",
            " ['img_5882748859075308881.jpg' 1]\n",
            " ['img_7562972799473713489.jpg' 1]\n",
            " ['img_829419087261051095.jpg' 1]\n",
            " ['img_6453119970492421134.jpg' 1]\n",
            " ['img_4189121449104865367.jpg' 1]\n",
            " ['img_3768705046218841477.jpg' 1]\n",
            " ['img_7432601586707751103.jpg' 1]\n",
            " ['img_318883629776419917.jpg' 1]\n",
            " ['img_6068328486169206149.jpg' 2]\n",
            " ['img_3751188215019143871.jpg' 1]\n",
            " ['img_2990304631921044895.jpg' 1]\n",
            " ['img_4362101259165710930.jpg' 2]\n",
            " ['img_972668160331506727.jpg' 2]\n",
            " ['img_7789226562806226056.jpg' 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ogGYnwQQWn"
      },
      "source": [
        "df_for_export = pd.DataFrame(predict_labels,columns=['file_name', 'class_id'])\n",
        "\n",
        "df_for_export.to_csv('resnet20Diamantaras.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssoAUmyJQUg1",
        "outputId": "06bf72c2-b926-4eff-899b-2a5c4f3ce5ca"
      },
      "source": [
        "print(df_for_export)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        file_name class_id\n",
            "0     img_6309102362127931879.jpg        0\n",
            "1     img_2031896927656989520.jpg        0\n",
            "2     img_4693592482016108254.jpg        1\n",
            "3     img_1731353163814999872.jpg        2\n",
            "4     img_4270405616056570211.jpg        2\n",
            "...                           ...      ...\n",
            "1163  img_3751188215019143871.jpg        1\n",
            "1164  img_2990304631921044895.jpg        1\n",
            "1165  img_4362101259165710930.jpg        2\n",
            "1166   img_972668160331506727.jpg        2\n",
            "1167  img_7789226562806226056.jpg        1\n",
            "\n",
            "[1168 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}